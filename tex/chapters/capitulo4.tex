\chapter[TRANSFORMACIONES LINEALES]{TRANSFORMACIONES \\ LINEALES}
%\startcontents
\printchaptertableofcontents

Las transformaciones lineales son un pilar esencial en el vasto terreno de las matemáticas, particularmente en el ámbito de álgebra lineal. Para comprender la magnitud de su influencia, es imperativo sumergirse en la esencia misma de estas transformaciones y explorar sus aplicaciones en diversos campos.

Una transformación lineal es, en esencia, una función matemática que preserva la estructura algebraica de los vectores. Al aplicar una transformación lineal a la combinación lineal de dos vectores, los resultados son análogos a la combinación lineal de las transformaciones individuales de cada vector. Este comportamiento de preservación de la linealidad es una característica clave que distingue a las transformaciones lineales y las eleva a una posición central en la teoría algebraica.

%En el fondo de estas transformaciones reside la preservación de las operaciones fundamentales: la suma y la multiplicación por escalares. Cuando aplicamos una transformación lineal a la suma de dos vectores, el resultado es la suma de las transformaciones lineales de cada vector individual. Similarmente, la multiplicación de un vector por un escalar antes de la transformación lineal es equivalente a multiplicar la transformación lineal por ese mismo escalar. Estas propiedades fundamentales son cruciales para entender la coherencia y la estructura que las transformaciones lineales aportan al álgebra lineal.

La aplicabilidad de las transformaciones lineales se extiende a diversos campos de estudio. En el ámbito de la resolución de sistemas de ecuaciones lineales, las transformaciones lineales ofrecen herramientas poderosas para entender y abordar problemas complejos. Además, en el análisis de estructuras algebraicas, como espacios vectoriales y grupos, las transformaciones lineales juegan un papel vital al proporcionar una lente única para examinar las propiedades intrínsecas de estos objetos matemáticos.

Al profundizar en las propiedades y aplicaciones de las transformaciones lineales, se revela un panorama rico y complejo. Desde la diagonalización de matrices hasta la representación canónica de formas cuadráticas, las transformaciones lineales ofrecen un marco conceptual robusto para abordar una variedad de problemas matemáticos.

Las transformaciones lineales no solo son conceptos abstractos en el ámbito de álgebra lineal, sino que constituyen la esencia misma de la coherencia algebraica. Su estudio no solo enriquece nuestra comprensión de las estructuras matemáticas, sino que también desbloquea un conjunto diverso de herramientas analíticas con aplicaciones prácticas significativas.

\section{Definición y ejemplos}

\begin{definition}\label{def:operatorlineal}
    Sean $V$ y $W$ dos espacios vectoriales sobre $K = \RR$. Se dice que una función
    \begin{align*}
        T: V & \longrightarrow W \\
        \mathbb{v} & \longmapsto T\mathbb{v} = \mathbb{w}
    \end{align*}
    es una transformación lineal de $V$ en $W$ si cumple que para cada $\mathbb{u}$, $\mathbb{v} \in V$ y $\alpha \in K$\infoBulle{A una transformación lineal también se le puede llamar operador lineal.}
    \begin{enumerate}[label=\roman*)]
        \item $T(\mathbb{u} + \mathbb{v}) = T\mathbb{u} + T\mathbb{v}$.
        \item $T(\alpha \mathbb{u}) = \alpha T\mathbb{u}$.
    \end{enumerate}
\end{definition}

\begin{notation}
    Se escriben indistintamente $T\mathbb{v}$ y $T(\mathbb{v})$. Denotan lo mismo; las dos se leen “$T$ de $\mathbb{v}$”. Esto es análogo a la notación funcional $f(x)$, que se lee “$f$ de $x$”.
\end{notation}

\begin{observation}
    La notación $T: V \longrightarrow W$ indica que $T$ toma el espacio vectorial real $V$ y lo lleva al espacio vectorial real $W$; esto es, $T$ es una función con $V$ como su dominio y un subconjunto de $W$ como su imagen.
\end{observation}

\begin{example}
    Veamos si
    \begin{align*}
        T: \RR[2] & \longrightarrow \RR[2] \\
        \begin{pmatrix}
            x \\
            y
        \end{pmatrix} & \longmapsto T \begin{pmatrix}
            x \\
            y
        \end{pmatrix} = \begin{pmatrix*}[r]
            x \\
            -y
        \end{pmatrix*}
    \end{align*}
    es una transformación lineal. En este caso, $T: V \longrightarrow W$ es $T: \RR[2] \longrightarrow \RR[2]$, además $\RR[2]$ es un espacio vectorial sobre $\RR$. Notemos que $T$ admite una interpretación geométrica sencilla como se muestra en la figura \ref{HDFDDFHUYFGHFUYGFFGUY}, así se comprueba que $T$ es función. Ahora se tiene\sideFigure[\label{HDFDDFHUYFGHFUYGFFGUY}Transformación de reflexión respecto al eje $x$]{
    \begin{tikzpicture}[scale=0.83]
        \draw[thick,-Stealth] (-1,0) -- (5,0);
        \draw[thick,Stealth-Stealth] (0,-5.5) -- (0,5.5);
        \draw[dash pattern=on 3pt off 3pt] (0,4) node[left] {$y$} -- (4,4) -- (4,-4) -- (0,-4) node[left] {$-y$};
        \draw[thick,-latex] (0,0) -- (4,4) node[above] {$\begin{pmatrix}
            x \\
            y
        \end{pmatrix}$};
        \draw[thick,-latex] (0,0) -- (4,-4) node[below] {$\begin{pmatrix*}[r]
            x \\
            -y
        \end{pmatrix*}$};
        \node at (0,0) [below left] {$\mathbb{0}$};
        \node at (4,0) [above right] {$x$};
        \node at (2,2) [above,rotate=45] {$\mathbb{u}$};
        \node at (2,-2) [below,rotate=-45] {$\mathbb{w} = T\mathbb{u}$};
    \end{tikzpicture}
    }
    \begin{enumerate}[label=\roman*)]
        \item Sea $\mathbb{u}$, $\mathbb{v} \in \RR[2]$ con $\mathbb{u} = \begin{pmatrix}
            x_1 \\
            y_1
        \end{pmatrix}$, $\mathbb{v} = \begin{pmatrix}
            x_2 \\
            y_2
        \end{pmatrix}$. Entonces
        \begin{align*}
            T(\mathbb{u} + \mathbb{v}) & = T\left( \begin{pmatrix}
                x_1 \\
                y_1
            \end{pmatrix} + \begin{pmatrix}
                x_2 \\
                y_2
            \end{pmatrix} \right) \\
            & = T \begin{pmatrix}
                x_1 + x_2 \\
                y_1 + y_2
            \end{pmatrix} \\
            & = \begin{pmatrix}
                x_1 + x_2 \\
                -(y_1 + y_2)
            \end{pmatrix} \\
            & = \begin{pmatrix}
                x_1 + x_2 \\
                -y_1 + (-y_2)
            \end{pmatrix} \\
            & = \begin{pmatrix*}[r]
                x_1 \\
                -y_1
            \end{pmatrix*} + \begin{pmatrix*}[r]
                x_2 \\
                -y_2
            \end{pmatrix*} \\
            & = T\mathbb{u} + T\mathbb{v}
        \end{align*}
        Por tanto $T(\mathbb{u} + \mathbb{v}) = T\mathbb{u} + T\mathbb{v}$.\newpage
        \item Sea $\mathbb{u} \in \RR[2]$ con $\mathbb{u} = \begin{pmatrix}
            x_1 \\
            y_1
        \end{pmatrix}$ y $\alpha \in \RR$. Entonces
        \begin{align*}
            T(\alpha \mathbb{u}) & = T \left( \alpha \begin{pmatrix}
                x_1 \\
                y_1
            \end{pmatrix} \right) \\
            & = T \begin{pmatrix}
                \alpha x_1 \\
                \alpha y_1
            \end{pmatrix} \\
            & = \begin{pmatrix*}[r]
                \alpha x_1 \\
                - \alpha y_1
            \end{pmatrix*} \\
            & = \alpha \begin{pmatrix*}[r]
                x_1 \\
                -y_1
            \end{pmatrix*} \\
            & = \alpha T \mathbb{u}
        \end{align*}
        Por tanto, $T(\alpha \mathbb{u}) = \alpha T\mathbb{u}$.
    \end{enumerate}
    Por tanto, $T$ es una transformación lineal de $\RR[2]$ a $\RR[2]$.
\end{example}

\begin{example}\label{tl:rotacion}
    Supongamos que el vector $\mathbb{v}$ se rota un ángulo $\theta$ (medido en grados o radianes) en sentido contrario al de las manecillas del reloj. Llamemos a este nuevo vector rotado $\mathbb{v}'$. Entonces como se ve en la figura \ref{fig:rotado1}, si $r$ denota la longitud de $\mathbb{v}$, entonces\sideFigure[\label{fig:rotado1}Transformación de rotación]{
    \begin{center}
        \begin{tikzpicture}[scale=0.76]
            \coordinate (A) at (0,0);
            \draw[-Stealth,thick] (-1,0) -- (5.5,0) node[right] {$x$} coordinate (B);
            \draw[-Stealth,thick] (0,-1) -- (0,5.5) node[above] {$y$};
            \draw[dash pattern=on 3pt off 3pt,thin] (3,0) -- (3,4) -- (0,4);
            \draw[dash pattern=on 3pt off 3pt,thin] (4.2,0) -- (4.2,1.6) -- (0,1.6);
            \draw[-latex,thick] (0,0) -- (3,4) coordinate(D);
            \draw[-latex,thick] (0,0) -- (4.2,1.6) coordinate(C);
            \node at (3,4) [right] {$\mathbb{v}' = \begin{pmatrix}
                x' \\
                y'
            \end{pmatrix}$};
            \node at (4.2,1.6) [right] {$\mathbb{v} = \begin{pmatrix}
                x \\
                y
            \end{pmatrix}$};
            \pic[draw, -latex, "$\alpha$", angle eccentricity=1.3,angle radius=1cm] {angle = B--A--C};
            \pic[draw, -latex, "$\theta$", angle eccentricity=1.3,angle radius=0.8cm] {angle = C--A--D};
            \pic[draw, -latex, "$\theta + \alpha$", angle eccentricity=1.3,angle radius=1.55cm] {angle = B--A--D};
            \node at (0,0) [below left] {$\mathbb{0}$};
        \end{tikzpicture}
    \end{center}
    }
    \marginElement{\justify
    \begin{center}
        \colorbox{gray!20}{\parbox[c]{\dimexpr\linewidth-3pt-2\fboxsep-2\fboxrule}{
            La transformación lineal de rotación es un proceso matemático que gira un objeto alrededor de un punto fijo. En un espacio bidimensional, la rotación se puede describir mediante matrices de rotación como
            $$\begin{pmatrix}
                x' \\
                y'
            \end{pmatrix} = \begin{bmatrix*}[r]
                \cos \theta & - \sen \theta \\
                \sen \theta & \cos \theta
            \end{bmatrix*} \begin{bmatrix}
                x \\
                y
            \end{bmatrix}$$
            Estas matrices aplican operaciones lineales para cambiar las coordenadas del objeto y lograr la rotación deseada. La trigonometría es fundamental en la formulación de estas matrices, y la aplicación repetida de rotaciones puede dar lugar a transformaciones más complejas.
        }}
    \end{center}
    }
    \begin{equation}
        x = r \cos(\alpha), \quad y = r \sen(\alpha)
    \end{equation}
    y
    \begin{equation}
        x' = r \cos(\theta + \alpha), \quad y' = r \sen(\theta + \alpha)
    \end{equation}
    Entonces
    \begin{align*}
        x' & = r \big( \cos(\theta) \cos(\alpha) - \sen(\theta) \sen(\alpha) \big) \\
        & = r \cos(\theta) \cos(\alpha) - r \sen(\theta) \sen(\alpha) \\
        & = x \cos(\theta) - y \sen(\theta)
    \end{align*}
    De manera análoga,
    \begin{align*}
        y' & = \big( \cos(\theta) \sen(\alpha) + \cos(\alpha) \sen(\theta) \big) \\
        & = r \cos(\theta) \sen(\alpha) + r \cos(\alpha) \sen(\theta) \\
        & = y \cos(\theta) + x \sen(\theta)
    \end{align*}
    Así pues, sea
    \begin{align*}
        T: \RR[2] & \longrightarrow \RR[2] \\
        \begin{pmatrix}
            x \\
            y
        \end{pmatrix} & \longmapsto T \begin{pmatrix}
            x \\
            y
        \end{pmatrix} = \begin{pmatrix}
            x \cos \theta - y \sen \theta \\
            x \sen \theta + y \cos \theta
        \end{pmatrix}
    \end{align*}
    con $0 \leq \theta < 2 \pi$ y $r > 0$ donde $r = \sqrt{x^2+y^2}$. Probemos que $T$ es transformación lineal:
    \begin{enumerate}[label=\roman*)]
        \item Sea $\mathbb{u}$, $\mathbb{v} \in \RR[2]$ con $\mathbb{u} = \begin{pmatrix}
            x \\
            y
        \end{pmatrix}$, $\mathbb{v} = \begin{pmatrix}
            x' \\
            y'
        \end{pmatrix}$. Entonces
        \begin{align*}
            T(\mathbb{u} + \mathbb{v}) & = T \begin{pmatrix}
                x + x' \\
                y + y'
            \end{pmatrix} \\
            & = \begin{pmatrix}
                (x + x') \cos \theta - (y + y') \sen \theta \\
                (x + x') \sen \theta + (y + y') \cos \theta
            \end{pmatrix} \\
            & = \begin{pmatrix}
                x \cos \theta + x' \cos \theta - y \sen \theta - y' \sen \theta \\
                x \sen \theta + x' \sen \theta + y \cos \theta + y' \cos \theta
            \end{pmatrix} \\
            & = \begin{pmatrix}
                x \cos \theta - y \sen \theta \\
                x \sen \theta + y \cos \theta
            \end{pmatrix} + \begin{pmatrix}
                x' \cos \theta - y' \sen \theta \\
                x' \sen \theta - y' \cos \theta
            \end{pmatrix} \\
            & = T\mathbb{u} + T\mathbb{v}
        \end{align*}
        Por tanto $T(\mathbb{u} + \mathbb{v}) = T\mathbb{u} + T\mathbb{v}$.
        \item Se deja como ejercicio al lector.
    \end{enumerate}
    Por tanto, $T$ es una transformación lineal de $\RR[2]$ a $\RR[2]$.
\end{example}

\begin{example}
    Veamos si
    \begin{align*}
        T: \RR[2] & \longrightarrow \RR[3] \\
        \begin{pmatrix}
            x \\
            y
        \end{pmatrix} & \longmapsto T \begin{pmatrix}
            x \\
            y
        \end{pmatrix} = \begin{pmatrix}
            x + y \\
            x - y \\
            2y
        \end{pmatrix}
    \end{align*}
    es una transformación lineal.
    \begin{enumerate}[label=\roman*)]
        \item Sea $\mathbb{u}$, $\mathbb{v} \in \RR[2]$ con $\mathbb{u} = \begin{pmatrix}
            x_1 \\
            y_1
        \end{pmatrix}$, $\mathbb{v} =  \begin{pmatrix}
            x_2 \\
            y_2
        \end{pmatrix}$. Entonces
        \begin{align*}
            T(\mathbb{u} + \mathbb{v}) & = T \left( \begin{pmatrix}
                x_1 \\
                y_1
            \end{pmatrix} + \begin{pmatrix}
                x_2 \\
                y_2
            \end{pmatrix} \right) \\
            & = T \begin{pmatrix}
                x_1 + x_2 \\
                y_1 + y_2
            \end{pmatrix} \\
            & = \begin{pmatrix}
                x_1 + x_2 + y_1 + y_2 \\
                x_1 + x_2 - (y_1 + y_2) \\
                2(y_1 + y_2)
            \end{pmatrix} \\
            & = \begin{pmatrix}
                x_1 + y_1 + x_2 + y_2 \\
                x_1 - y_1 + x_2 - y_2 \\
                2y_1 + 2y_2
            \end{pmatrix} \\
            & = \begin{pmatrix}
                x_1 + y_1 \\
                x_1 - y_1 \\
                2y_1
            \end{pmatrix} + \begin{pmatrix}
                x_2 + y_2 \\
                x_2 - y_2 \\
                2y_2
            \end{pmatrix} \\
            & = T\mathbb{u} + T\mathbb{v}
        \end{align*}
        Por tanto $T(\mathbb{u} + \mathbb{v}) = T\mathbb{u} + T\mathbb{v}$.
        \item Sea $\mathbb{u} \in \RR[2]$ con $\mathbb{u} = \begin{pmatrix}
            x_1 \\
            y_1
        \end{pmatrix}$ y $\alpha \in \RR$. Entonces
        \begin{align*}
            T(\alpha \mathbb{u}) & = T \left( \alpha \begin{pmatrix}
                x_1 \\
                y_1
            \end{pmatrix} \right) \\
            & = T \begin{pmatrix}
                \alpha x_1 \\
                \alpha y_1
            \end{pmatrix} \\
            & = \begin{pmatrix}
                \alpha x_1 + \alpha y_1 \\
                \alpha x_1 - \alpha y_1 \\
                2 \alpha y_1
            \end{pmatrix} \\
            & = \alpha \begin{pmatrix}
                x_1 + y_1 \\
                x_1 - y_1 \\
                2 y_1
            \end{pmatrix} \\
            & = \alpha T \mathbb{u}
        \end{align*}
        Por tanto, $T(\alpha \mathbb{u}) = \alpha T\mathbb{u}$.
    \end{enumerate}
    Por tanto, $T$ es una transformación lineal de $\RR[2]$ a $\RR[3]$.
\end{example}

\begin{definition}
    A la transformación lineal dada por $\mathcal{O} \mathbb{u} = \mathbb{0}_{W}$, $\forall \mathbb{u} \in V$ siendo $\mathcal{O}:V \longrightarrow W$, se le llama transformación cero.
\end{definition}

\begin{definition}
    A la transformación lineal dada por $I \mathbb{u} = \mathbb{u}$, $\forall \mathbb{u} \in V$ siendo $I:V \longrightarrow V$, se le llama transformación identidad.
\end{definition}

\newpage

\begin{example}
    Sea $T: \RR[n] \longrightarrow \RR[m]$ definida como
    $$T\mathbb{x} = A\mathbb{x}$$
    siendo $A \in \matrizmn$. Verifique que $T$ es una transformación lineal. \\
    \solucion Sea
    \begin{align*}
        T: \RR[n] & \longrightarrow \RR[m] \\
        \mathbb{x} & \longmapsto T\mathbb{x} = A\mathbb{x}
    \end{align*}
    Probemos que $T$ es una transformación lineal:
    \begin{enumerate}[label=\roman*)]
        \item Sea $\mathbb{x}$, $\mathbb{y} \in \RR[n]$. Entonces
        \begin{align*}
            T(\mathbb{x} + \mathbb{y}) & = A(\mathbb{x} + \mathbb{y}) \\
            & = A\mathbb{x} + \mathbb{y} \\
            & = T\mathbb{x} + T\mathbb{y}
        \end{align*}
        Por tanto $T(\mathbb{x} + \mathbb{y}) = T\mathbb{x} + T\mathbb{y}$.
        \item Sea $\mathbb{x} \in \RR[n]$ y $\alpha \in \RR$. Entonces
        \begin{align*}
            T(\alpha \mathbb{x}) & = A(\alpha \mathbb{x}) \\
            & = \alpha A \mathbb{x} \\
            & = \alpha T \mathbb{x}
        \end{align*}
        Por tanto, $T(\alpha \mathbb{x}) = \alpha T\mathbb{x}$.
    \end{enumerate}
    Por tanto, $T$ es una transformación lineal de $\RR[n]$ a $\RR[m]$.
\end{example}

\begin{example}
    Sea
    \begin{align*}
        T:C[0,  1] & \longrightarrow \RR \\
        f & \longmapsto T_{f} = \int_0^1 f(x) dx
    \end{align*}
    donde $C[0,  1]$ es el conjunto de funciones $f:[0,  1] \longrightarrow \RR$ continuas. Notemos que $T$ admite una interpretación geométrica sencilla, tomando una función arbitraria en $C[0,  1]$ como se muestra en la figura \ref{IDIDIIDKDKDKKK}. Así pues, comprobemos que $T$ es una transformación lineal:\sideFigure[\label{IDIDIIDKDKDKKK}Operador integral]{
    \begin{center}
        \begin{tikzpicture}[declare function={
        a=0;
        b=3;
        f(\x)=exp(\x) - \x + 1;
        }]
            \begin{axis}[
            axis lines=middle,
            xlabel=$x$,
            ylabel=$y$,
            xmin=-0.5,
            xmax=3,
            ymin=-0.75,
            ymax=8,
            ytick=\empty,
            xtick={2},
            xticklabels={$1$},
            width=6.3cm,
            height=10cm,
            xlabel style={
                anchor=west,
            },
            ylabel style={
                anchor=south,
            },
            axis line style={thick,-Stealth},
            ]
                \addplot[name path=A, gray, thick, domain=0.01:2, smooth] {f(x)};
                \path[name path=B] (\pgfkeysvalueof{/pgfplots/xmin},0) -- (\pgfkeysvalueof{/pgfplots/xmax},0);
                \addplot[gray!20] fill between [of=A and B, soft clip={domain=a:2},];
                \addplot[dashed, thick,->,>={}] coordinates {(2,0)(2,8)};
                \path ({(2+a)/2},{f((2+a)/2)/2}) node{$\displaystyle \int_0^1 f(x)$};
                \path (0,0) node[below left] {$0$};
                \addplot[thick,->,>={}] coordinates {(0,6)(0,0)(2.5,0)};
            \end{axis}
        \end{tikzpicture}
    \end{center}
    }
    \begin{enumerate}[label=\roman*)]
        \item Sea $f$, $g \in C[0,  1]$. Entonces
        \begin{align*}
            T(f + g) & = \int_0^1 (f + g)(x) dx \\
            & = \int_0^1 f(x) + g(x) dx \\
            & = \int_0^1 f(x) dx + \int_0^1 g(x) dx \\
            & = T_{f} + T_{g}
        \end{align*}
        Por tanto, $T(f + g) = T_{f} + T_{g}$.
        \item[ii)] Sea $f \in C[0,  1]$ y $\alpha \in \RR$. Entonces
        \begin{align*}
            T(\alpha f) & = \int_0^1 (\alpha f)(x) dx \\
            & = \int_0^1 \alpha f(x) dx \\
            & = \alpha \int_0^1 f(x) dx \\
            & = \alpha T_{f}
        \end{align*}
        Por tanto, $T(\alpha f) = \alpha T_{f}$.
    \end{enumerate}
    Por tanto, $T$ es una transformación lineal.
\end{example}

\begin{example}
    Sea
    \begin{align*}
        T:C[0,  1] & \longrightarrow \RR \\
        f & \longmapsto T_{f} = f(0) + 1
    \end{align*}
    donde $C[0,  1]$ es el conjunto de funciones $f:[0,  1] \longrightarrow \RR$ continuas. Notemos que $T$ es no lineal, pues tenemos que
    $$T(f + g) = (f + g) + 1 = f(0) + g(0) + 1$$
    y
    $$T_{f} + T_{g} = [f(0) + 1] + [g(0) + 1] = f(0) + g(0) + 2$$
\end{example}

\begin{theorem}
    Sean $V$ y $W$ espacios vectoriales sobre $K$. Si $T: V \longrightarrow W$ es una transformación lineal, entonces
    \begin{enumerate}[label=\roman*)]
        \item $T\mathbb{0}_V = \mathbb{0}_W$.
        \item $T(-\mathbb{u}) = -T\mathbb{u}$.
        \item $T(\mathbb{u} - \mathbb{v}) = T\mathbb{u} - T\mathbb{v}$.
        \item $T(\alpha_1 \mathbb{u}_1 + \alpha_2 \mathbb{u}_2 + \cdots + \alpha_n \mathbb{u}_n) = \alpha_1 T\mathbb{u}_1 + \alpha_2 T\mathbb{u}_2 + \cdots + \alpha_n T\mathbb{u}_n$ con $\alpha_1$, $\alpha_2$, $\dots$, $\alpha_n \in K$ y $\mathbb{u}_1$, $\mathbb{u}_2$, $\dots$, $\mathbb{u}_n \in V$.
    \end{enumerate}
    \demostracion
    \begin{enumerate}[label=\roman*)]
        \item Tenemos que
        $$\mathbb{0}_V = \mathbb{0}_V + \mathbb{0}_V$$
        así que
        \begin{align*}
            T\mathbb{0}_V & = T(\mathbb{0}_V + \mathbb{0}_V) \\
            & = T\mathbb{0}_V + T\mathbb{0}_V
        \end{align*}
        Ahora
        \begin{align*}
            \mathbb{0}_W & = T\mathbb{0}_V + (-T\mathbb{0}_V) \\
            & = T\mathbb{0}_V + T\mathbb{0}_V + (-T\mathbb{0}_V) \\
            & = T\mathbb{0}_V + \big( T\mathbb{0}_V + (-T\mathbb{0}_V) \big) \\
            & = T\mathbb{0}_V + \mathbb{0}_W \\
            & = T\mathbb{0}_V
        \end{align*}
        Por tanto, $T\mathbb{0}_V = \mathbb{0}_W$.
        \item Sea $\mathbb{u} \in V$, entonces
        \begin{align*}
            T\mathbb{u} + T(-\mathbb{u}) & = T\big( \mathbb{u} + (-\mathbb{u}) \big) \\
            & = T(\mathbb{0}_V) \\
            & = \mathbb{0}_W
        \end{align*}
        Por tanto, $T(-\mathbb{u}) = -T\mathbb{u}$.
        \item Sean $\mathbb{u}$, $\mathbb{v} \in V$, entonces
        \begin{align*}
            T(\mathbb{u} - \mathbb{v}) & = T\mathbb{u} + T(-\mathbb{v}) \\
            & = T\mathbb{u} - T\mathbb{v}
        \end{align*}
        Por tanto, $T(\mathbb{u} - \mathbb{v}) = T\mathbb{u} - T\mathbb{v}$.
        \item Sean $\alpha_1$, $\alpha_2$, $\dots$, $\alpha_n \in K$ y sean $\mathbb{u}_1$, $\mathbb{u}_2$, $\dots$, $\mathbb{u}_n \in V$. Procedamos por inducción sobre $n$. Si $n = 2$, entonces
        \begin{align*}
            T(\alpha_1 \mathbb{u}_1 + \alpha_2 \mathbb{u}_2) & = T(\alpha_1 \mathbb{u}_1) + T(\alpha_2 \mathbb{u}_2) \\
            & = \alpha_1 T\mathbb{u}_1 + \alpha_2 T\mathbb{u}_2
        \end{align*}
        Supongamos que se cumple para $k$, es decir,
        $$T(\alpha_1 \mathbb{u}_1 + \alpha_2 \mathbb{u}_2 + \cdots + \alpha_k \mathbb{u}_k) = \alpha_1 T\mathbb{u}_1 + \alpha_2 T\mathbb{u}_2 + \cdots + \alpha_k T\mathbb{u}_k$$
        Probemos ahora para $k+1$,
        \begin{align*}
            T(\alpha_1 \mathbb{u}_1 + \alpha_2 \mathbb{u}_2 + \cdots + \alpha_k \mathbb{u}_k + \alpha_{k+1} \mathbb{u}_{k+1}) & = T(\alpha_1 \mathbb{u}_1 + \alpha_2 \mathbb{u}_2 + \cdots + \alpha_k \mathbb{u}_k) + T(\alpha_{k+1} \mathbb{u}_{k+1}) \\
            & = \alpha_1 T\mathbb{u}_1 + \alpha_2 T\mathbb{u}_2 + \cdots + \alpha_k T\mathbb{u}_k + \alpha_{k+1} T\mathbb{u}_{k+1}
        \end{align*}
        Por tanto,
        $$T(\alpha_1 \mathbb{u}_1 + \alpha_2 \mathbb{u}_2 + \cdots + \alpha_n \mathbb{u}_n) = \alpha_1 T\mathbb{u}_1 + \alpha_2 T\mathbb{u}_2 + \cdots + \alpha_n T\mathbb{u}_n$$
    \end{enumerate}
\end{theorem}

\begin{theorem}\label{theorem:LAKAAKLKSKSKSSIIS}
    Sean $V$ y $W$ dos espacios vectoriales sobre $K$ y sean $T_1$, $T_2:V \longrightarrow W$ dos transformaciones lineales tales que
    $$T_1(\mathbb{v}_i) = T_2(\mathbb{v}_i), \text{ para } i = 1,  2,  \dots,  n$$
    siendo $\{ \mathbb{v}_1,  \mathbb{v}_2,  \dots,  \mathbb{v}_n \}$ una base de $V$, entonces $T_1 = T_2$. \\
    \demostracion
    Sea $\{ \mathbb{v}_1,  \mathbb{v}_2,  \dots,  \mathbb{v}_n \}$ una base de $V$. Basta probar que
    $$T_1\mathbb{v} = T_2 \mathbb{v}, \forall \mathbb{v} \in V$$
    Así pues, sea $\mathbb{v} \in V$ un elemento arbitrario, entonces
    \begin{equation}
        \mathbb{v} = \alpha_1 \mathbb{v}_1 + \alpha_2 \mathbb{v}_2 + \cdots + \alpha_n \mathbb{v}_n \label{JAJJSJSKSKDKKSKDSKDKIDD}
    \end{equation}
    con $\alpha_i \in K$ para $i = 1$, $2$, $\dots$, $n$, ya que $\{ \mathbb{v}_1,  \mathbb{v}_2,  \dots,  \mathbb{v}_n \}$ es una base de $V$. De \eqref{JAJJSJSKSKDKKSKDSKDKIDD},
    \begin{align*}
        T_1 \mathbb{v} & = T_1(\alpha_1 \mathbb{v}_1 + \alpha_2 \mathbb{v}_2 + \cdots + \alpha_n \mathbb{v}_n) \\
        & = T_1(\alpha_1 \mathbb{v}_1) + T_1(\alpha_2 \mathbb{v}_2) + \cdots + T_1(\alpha_n \mathbb{v}_n) \\
        & = \alpha_1 T_1 \mathbb{v}_1 + \alpha_2 T_1 \mathbb{v}_2 + \cdots + \alpha_n T_1 \mathbb{v}_n \\
        & = \alpha_1 T_2 \mathbb{v}_1 + \alpha_2 T_2 \mathbb{v}_2 + \cdots + \alpha_n T_2 \mathbb{v}_n \\
        & = T_2(\alpha_1 \mathbb{v}_1) + T_2(\alpha_2 \mathbb{v}_2) + \cdots + T_2(\alpha_n \mathbb{v}_n) \\
        & = T_2(\alpha_1 \mathbb{v}_1 + \alpha_2 \mathbb{v}_2 + \cdots + \alpha_n \mathbb{v}_n) \\
        & = T_2 \mathbb{v}
    \end{align*}
    Por tanto, $T_1 \mathbb{v} = T_2 \mathbb{v}$, $\forall \mathbb{v} \in V$. Así, $T_1 = T_2$.
\end{theorem}

\section{Núcleo e imagen de una transformación lineal}

\begin{definition}
    Sean $V$ y $W$ espacios vectoriales sobre $K$ y $T:V \longrightarrow W$ una transformación lineal. Se define:
    \begin{enumerate}[label=\roman*)]
        \item El núcleo de la transformación lineal $T$, como
        $$\Nuc(T) = \left\{ \mathbb{v} \in V \mid T\mathbb{v} = \mathbb{0}_W \right\}$$
        \item La imagen de la transformación lineal $T$, como
        $$\Ima(T) = \left\{ \mathbb{w} \in W \mid T\mathbb{v} = \mathbb{w}, \text{ para algún } \mathbb{v} \in V \right\}$$
        \item La nulidad de la transformación lineal $T$, como
        $$\nu(T) = \Dim \big( \Nuc(T) \big)$$
        \item El rango de la transformación lineal $T$, como
        $$\rho(T) = \Dim \big( \Ima(T) \big)$$
    \end{enumerate}
\end{definition}

\newpage

\begin{theorem}
    Sean $V$ y $W$ espacios vectoriales sobre $K$ y $T:V \longrightarrow W$ una transformación lineal, entonces $\Nuc(T)$ es subespacio de $V$ e $\Ima(T)$ es subespacio de $W$. \\
    \demostracion
    Primero, probemos que $\Nuc(T)$ es subespacio de $V$. Sean $\mathbb{v}_1$, $\mathbb{v}_2 \in \Nuc(T)$ y $\alpha \in K$, entonces
    \begin{equation}
        T\mathbb{v}_1 = \mathbb{0}_W \quad \text{ y } \quad T\mathbb{v}_2 = \mathbb{0}_W
    \end{equation}
    Así,
    \begin{align*}
        T(\mathbb{v}_1 + \mathbb{v}_2) & = T\mathbb{v}_1 + T\mathbb{v}_2 \\
        & = \mathbb{0}_W + \mathbb{0}_W \\
        & = \mathbb{0}_W
    \end{align*}
    Entonces
    \begin{equation}
        \mathbb{v}_1 + \mathbb{v}_2 \in \Nuc(T) \label{JAUDJKDKDKDKD}
    \end{equation}
    Además
    \begin{align*}
        T(\alpha \mathbb{v}_1) & = \alpha T\mathbb{v}_1 \\
        & = \alpha \mathbb{0}_W \\
        & = \mathbb{0}_W
    \end{align*}
    Entonces
    \begin{equation}
        \alpha \mathbb{v}_1 \in \Nuc(T) \label{OSPWPEOSLDDPDPD}
    \end{equation}
    Por tanto, de \eqref{JAUDJKDKDKDKD} y \eqref{OSPWPEOSLDDPDPD}, $\Nuc(T)$ es subespacio de $V$.

    Ahora veamos que $\Ima(T)$ es subespacio de $W$. Sean $\mathbb{w}_1$, $\mathbb{w}_2 \in \Ima(T)$ y $\alpha \in K$, entonces
    \begin{equation}
        \mathbb{w}_1 = T\mathbb{v}_1, \text{ para algún } \mathbb{v}_1 \in V \quad \text{ y } \quad \mathbb{w}_2 = T\mathbb{v}_2, \text{ para algún } \mathbb{v}_2 \in V
    \end{equation}
    Así,
    \begin{align*}
        \mathbb{w}_1 + \mathbb{w}_2 & = T\mathbb{v}_1 + T\mathbb{v}_2 \\
        & = T(\mathbb{v}_1 + \mathbb{v}_2) \\
        & = T\mathbb{\mu}
    \end{align*}
    siendo $\mathbb{\mu} = \mathbb{v}_1 + \mathbb{v}_2$. Entonces
    \begin{equation}
        \mathbb{w}_1 + \mathbb{w}_2 \in \Ima(T) \label{IAISISKSKSKLS}
    \end{equation}
    Además
    \begin{align*}
        \alpha \mathbb{w}_1 & = \alpha T\mathbb{v}_1 \\
        & = T(\alpha \mathbb{v}_1) \\
        & = T(\mathbb{\upsilon})
    \end{align*}
    siendo $\mathbb{\upsilon} = \alpha \mathbb{v}_1$. Entonces
    \begin{equation}
        \alpha \mathbb{w}_1 \in \Ima(T) \label{ISOSPPSOSPASHSHSJ}
    \end{equation}
    Por tanto, de \eqref{IAISISKSKSKLS} y \eqref{ISOSPPSOSPASHSHSJ} $\Ima(T)$ es subespacio de $W$.
\end{theorem}

\begin{example}
    Dada la transformación lineal $T:\RR[4] \longrightarrow \RR[2]$ definida por
    $$T\begin{pmatrix}
        x \\
        y \\
        z \\
        w
    \end{pmatrix} = \begin{pmatrix}
        x + z \\
        y + w
    \end{pmatrix}$$
    Determine $\Nuc(T)$, $\Ima(T)$, $\nu(T)$ y $\rho(T)$. \newpage
    \solucion Por definición,
    \begin{align*}
        \Nuc(T) & = \left\{ \begin{pmatrix}
            x \\
            y \\
            z \\
            w
        \end{pmatrix} \in \RR[4] \mid T \begin{pmatrix}
            x \\
            y \\
            z \\
            w
        \end{pmatrix} = \begin{pmatrix}
            0 \\
            0
        \end{pmatrix} \right\} \\
        & = \left\{ \begin{pmatrix}
            x \\
            y \\
            z \\
            w
        \end{pmatrix} \in \RR[4] \mid \begin{pmatrix}
            x + z \\
            y + w
        \end{pmatrix} = \begin{pmatrix}
            0 \\
            0
        \end{pmatrix} \right\} \\
        & = \left\{ \begin{pmatrix}
            x \\
            y \\
            z \\
            w
        \end{pmatrix} \in \RR[4] \mid x + z = 0, \; y + w = 0 \right\} \\
        & = \left\{ \begin{pmatrix*}[r]
            x \\
            y \\
            -x \\
            -y
        \end{pmatrix*} \in \RR[4] \mid x,  y \in \RR \right\} \\
        & = \left\{ x \begin{pmatrix*}[r]
            1 \\
            0 \\
            -1 \\
            0
        \end{pmatrix*} + y \begin{pmatrix*}[r]
            0 \\
            1 \\
            0 \\
            -1
        \end{pmatrix*} \mid x,  y \in \RR \right\}
    \end{align*}
    Por tanto,
    $$\Nuc(T) = \Gen \left( \left\{ \begin{pmatrix*}[r]
        1 \\
        0 \\
        -1 \\
        0
    \end{pmatrix*},  \begin{pmatrix*}[r]
        0 \\
        1 \\
        0 \\
        -1
    \end{pmatrix*} \right\} \right)$$
    y como los vectores son l.i, entonces $\nu(T) = 2$. Ahora, por definición,
    \begin{align*}
        \Ima(T) & = \left\{ \begin{pmatrix}
            \gamma_1 \\
            \gamma_2
        \end{pmatrix} \in \RR[2] \mid T\begin{pmatrix}
            x \\
            y \\
            z \\
            w
        \end{pmatrix} = \begin{pmatrix}
            \gamma_1 \\
            \gamma_2
        \end{pmatrix}, \text{ para algún } \begin{pmatrix}
            x \\
            y \\
            z \\
            w
        \end{pmatrix} \in \RR[4] \right\} \\
        & = \left\{ \begin{pmatrix}
            \gamma_1 \\
            \gamma_2
        \end{pmatrix} \in \RR[2] \mid \begin{pmatrix}
            x + z \\
            y + w
        \end{pmatrix} = \begin{pmatrix}
            \gamma_1 \\
            \gamma_2
        \end{pmatrix}, \text{ para algún } \begin{pmatrix}
            x \\
            y \\
            z \\
            w
        \end{pmatrix} \in \RR[4] \right\} \\
        & = \left\{ \begin{pmatrix}
            \gamma_1 \\
            \gamma_2
        \end{pmatrix} = \begin{pmatrix}
            x + z \\
            y + w
        \end{pmatrix}, \text{ para algún } \begin{pmatrix}
            x \\
            y \\
            z \\
            w
        \end{pmatrix} \in \RR[4] \right\} \\
        & = \left\{ \begin{pmatrix}
            \gamma_1 \\
            \gamma_2
        \end{pmatrix} = x \begin{pmatrix}
            1 \\
            0
        \end{pmatrix} + y \begin{pmatrix}
            0 \\
            1
        \end{pmatrix} + z \begin{pmatrix}
            1 \\
            0
        \end{pmatrix} + w \begin{pmatrix}
            0 \\
            1
        \end{pmatrix}, \text{ para algún } x,  y,  z,  w \in \RR \right\} \\
        & = \left\{ \begin{pmatrix}
            \gamma_1 \\
            \gamma_2
        \end{pmatrix} = x \begin{pmatrix}
            1 \\
            0
        \end{pmatrix} + y \begin{pmatrix}
            0 \\
            1
        \end{pmatrix} + z \begin{pmatrix}
            1 \\
            0
        \end{pmatrix} + w \begin{pmatrix}
            0 \\
            1
        \end{pmatrix}, \text{ para algún } x,  y,  z,  w \in \RR \right\}
    \end{align*}
    Por tanto,
    $$\Ima(T) = \Gen \left( \left\{  \begin{pmatrix}
        1 \\
        0
    \end{pmatrix},  \begin{pmatrix}
        0 \\
        1
    \end{pmatrix},  \begin{pmatrix}
        1 \\
        0
    \end{pmatrix},  \begin{pmatrix}
        0 \\
        1
    \end{pmatrix} \right\} \right)$$
    y en este caso, vemos que solo dos vectores son l.i, así que $\rho(T) = 2$.
\end{example}

\begin{example}
    Sea $T: P_3(x) \longrightarrow P_2(x)$ una transformación lineal definida por
    $$Tp(x) = T \left( a_3x^3 + a_2x^2 + a_1x + a_0 \right) = a_2x^2 + a_1x + a_0$$
    Determine $\Nuc(T)$, $\Ima(T)$, $\nu(T)$ y $\rho(T)$. \newpage
    \solucion Por definición,
    \begin{align*}
        \Nuc(T) & = \left\{ p(x) \in P_3(x) \mid Tp(x) = 0 \right\} \\
        & = \left\{ p(x) \in P_3(x) \mid T \left( a_3x^3 + a_2x^2 + a_1x + a_0 \right) = 0 \right\} \\
        & = \left\{ p(x) \in P_3(x) \mid a_2x^2 + a_1x + a_0 = 0 \right\} \\
        & = \left\{ p(x) \in P_3(x) \mid a_0 = 0,  a_1 = 0,  a_2 = 0 \right\} \\
        & = \left\{ a_3x^3 + 0 \cdot x^2 + 0 \cdot x + 0 \cdot 0 \mid a_3 \in \RR \right\} \\
        & = \left\{ a_3x^3 \mid a_3 \in \RR \right\} \\
        & = \Gen \left( \left\{ x^3 \right\} \right)
    \end{align*}
    Por tanto,
    $$\Nuc(T) = \Gen \left( \left\{ x^3 \right\} \right)$$
    y por ser l.i, se sigue que $\nu(T) = 1$. Ahora, por definición,
    \begin{align*}
        \Ima(T) & = \left\{ q(x) \in P_2(x) \mid Tp(x) = q(x), \text{ para algún } p(x) \in P_3(x) \right\} \\
        & = \left\{ q(x) \in P_2(x) \mid a_2x^2 + a_1x + a_0 = q(x), \text{ para algún } p(x) \in P_3(x) \right\} \\
        & = \left\{ q(x) = a_2x^2 + a_1x + a_0 \mid a_2,  a_1,  a_0 \in \RR \right\} \\
        & = \left\{ a_2x^2 + a_1x + a_0 \mid a_2,  a_1,  a_0 \in \RR \right\} \\
        & = \Gen \left( \left\{ x^2,  x,  1 \right\} \right)
    \end{align*}
    Por tanto,
    $$\Ima(T) = \Gen \left( \left\{ x^2,  x,  1 \right\} \right)$$
    y como son l.i, entonces $\rho(T) = 3$.
\end{example}

\section{Representación matricial de una transformación lineal}

\begin{theorem}\label{matrix_representationtl}
    Sea $T: \RR[n] \longrightarrow \RR[m]$ una transformación lineal, entonces existe una única matriz $A_T \in \matrizmn$ tal que
    $$T\mathbb{x} = A_T\mathbb{x}, \; \forall \mathbb{x} \in \RR[n]$$
    A la matriz $A_T$, se le llama la representación matricial de la transformación lineal $T$. \\
    \demostracion Sea $\displaystyle \left\{ e_1 = \left( \begin{array}{c} 1 \\ 0 \\ \vdots \\ 0 \\ 0 \end{array} \right),  e_2 = \left( \begin{array}{c} 0 \\ 1 \\ \vdots \\ 0 \\ 0 \end{array} \right),  \dots,  e_n = \left( \begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{array} \right) \right\}$ la base canónica de $\RR[n]$. Sea
    $$Te_1 = \mathbb{w}_1 \in \RR[m],  Te_2 = \mathbb{w}_2 \in \RR[m],  \dots,  Te_n = \mathbb{w}_n \in \RR[m]$$
    siendo $\mathbb{w}_j = \begin{bmatrix}
        a_{1j} \\
        a_{2j} \\
        \vdots \\
        a_{mj}
    \end{bmatrix}$, para $j = 1,  2,  \dots,  n$. Sea $A_T = \begin{bmatrix}
        \mathbb{w}_1 & \mathbb{w}_2 & \cdots & \mathbb{w}_n
    \end{bmatrix}$ donde
    $$A_T = \begin{bmatrix}
        a_{11} & a_{12} & \cdots & a_{1n} \\
        a_{21} & a_{22} & \cdots & a_{2n} \\
        \vdots & & \ddots & \\
        a_{m1} & a_{m2} & \cdots & a_{mn}
    \end{bmatrix}$$\newpage\noindent
    Veamos lo siguiente
    $$Te_1 = \mathbb{w}_1 = \begin{bmatrix}
        a_{11} \\
        a_{21} \\
        \vdots \\
        a_{m1}
    \end{bmatrix} \quad \text{ y } \quad A_Te_1 = \begin{bmatrix}
        a_{11} \\
        a_{21} \\
        \vdots \\
        a_{m1}
    \end{bmatrix}$$
    entonces $Te_1 = A_Te_1$. Asimismo,
    $$Te_2 = \mathbb{w}_2 = \begin{bmatrix}
        a_{12} \\
        a_{22} \\
        \vdots \\
        a_{m2}
    \end{bmatrix} \quad \text{ y } \quad A_Te_2 = \begin{bmatrix}
        a_{12} \\
        a_{22} \\
        \vdots \\
        a_{m2}
    \end{bmatrix}$$
    entonces $Te_2 = A_Te_2$. Así pues,
    $$Te_n = \mathbb{w}_n = \begin{bmatrix}
        a_{1n} \\
        a_{2n} \\
        \vdots \\
        a_{mn}
    \end{bmatrix} \quad \text{ y } \quad A_Te_2 = \begin{bmatrix}
        a_{1n} \\
        a_{2n} \\
        \vdots \\
        a_{mn}
    \end{bmatrix}$$
    entonces $Te_n = A_Te_n$. Por el teorema \ref{theorem:LAKAAKLKSKSKSSIIS}, $T = A_T$.

    Ahora, veamos que $A_T$ es único. Supongamos que existe $B_T \in \matrizmn$ tal que
    $$T\mathbb{x} = B_T\mathbb{x}, \; \forall \mathbb{x} \in \RR[n]$$
    Así
    $$A_T\mathbb{x} - B_T\mathbb{x} = \mathbb{0}_{\RR[m]}$$
    de donde se sigue que
    $$A_T\mathbb{x} - B_T\mathbb{x} + B_T\mathbb{x} = \mathbb{0}_{\RR[m]} + B_T\mathbb{x}$$
    entonces
    $$A_T\mathbb{x} = B_T\mathbb{x}, \; \forall \mathbb{x} \in \RR[n]$$
    Por lo tanto, $A_T = B_T$, de donde se sigue que $A_T$ es única.
\end{theorem}

\begin{example}
    Sea $T:\RR[3] \longrightarrow \RR[4]$ definida por $T \begin{pmatrix}
        x \\
        y \\
        z
    \end{pmatrix} = \begin{bmatrix}
        x - y \\
        y + z \\
        2x - y - z \\
        - x + y + 2z
    \end{bmatrix}$. Determine $A_T$, $\Nuc(T)$, $\Ima(T)$, $\nu(T)$ y $\rho(T)$. \\
    \solucion Sea $\left\{ e_1 = \begin{pmatrix}
        1 \\
        0 \\
        0
    \end{pmatrix},  e_2 = \begin{pmatrix}
        0 \\
        1 \\
        0
    \end{pmatrix},  e_3 = \begin{pmatrix}
        0 \\
        0 \\
        1
    \end{pmatrix} \right\}$ la base canónica de $\RR[3]$. Ahora, por el teorema anterior,
    $$Te_1 = T\begin{pmatrix}
        1 \\
        0 \\
        0
    \end{pmatrix} = \begin{bmatrix*}[r]
        1 \\
        0 \\
        2 \\
        -1
    \end{bmatrix*} = \mathbb{w}_1, \quad Te_2 = T\begin{pmatrix}
        0 \\
        1 \\
        0
    \end{pmatrix} = \begin{bmatrix*}[r]
        -1 \\
        1 \\
        -1 \\
        1
    \end{bmatrix*} = \mathbb{w}_2, \quad Te_3 = T\begin{pmatrix}
        0 \\
        0 \\
        1
    \end{pmatrix} = \begin{bmatrix*}[r]
        0 \\
        1 \\
        -1 \\
        2
    \end{bmatrix*} = \mathbb{w}_3$$
    De esta forma,
    \begin{align*}
        A_T & = \begin{bmatrix}
            \mathbb{w}_1 & \mathbb{w}_2 & \mathbb{w}_3
        \end{bmatrix} \\
        & = \begin{bmatrix*}[r]
            1 & -1 & 0 \\
            0 & 1 & 1 \\
            2 & -1 & -1 \\
            -1 & 1 & 2
        \end{bmatrix*}
    \end{align*}
    es la representación matricial de $T$. Veamos lo siguiente: Para todo $\mathbb{x} \in \RR[3]$,
    \begin{align*}
        A_T\mathbb{x} & = \begin{bmatrix*}[r]
            1 & -1 & 0 \\
            0 & 1 & 1 \\
            2 & -1 & -1 \\
            -1 & 1 & 2
        \end{bmatrix*} \begin{pmatrix}
            x \\
            y \\
            z
        \end{pmatrix} \\
        & = \begin{bmatrix}
            x - y \\
            y + z \\
            2x - y - z \\
            - x + y + 2z
        \end{bmatrix} \\
        & = T \begin{pmatrix}
            x \\
            y \\
            z
        \end{pmatrix}
    \end{align*}
    Ahora,
    \begin{align*}
        \Nuc(T) & = \left\{ \mathbb{x} \in \RR[3] \mid T\mathbb{x} = \mathbb{0} \right\} \\
        & = \left\{ \begin{pmatrix}
            x \\
            y \\
            z
        \end{pmatrix} \in \RR[3] \mid \begin{bmatrix}
            x - y \\
            y + z \\
            2x - y - z \\
            - x + y + 2z
        \end{bmatrix} = \begin{pmatrix}
            0 \\
            0 \\
            0 \\
            0
        \end{pmatrix} \right\}
    \end{align*}
    entonces
    \begin{align*}
        x - y & = 0 \\
        y + z & = 0 \\
        2x - y - z & = 0 \\
        - x + y + 2z & = 0
    \end{align*}
    de donde $x = y = z = 0$. Por lo que $\Nuc(T) = \left\{ \begin{pmatrix}
        0 \\
        0 \\
        0
    \end{pmatrix} \right\}$, entonces $\nu(T) = 0$. Finalmente,
    \begin{align*}
        \Ima(T) & = \left\{ \mathbb{y} \in \RR[4] \mid T\mathbb{x} = \mathbb{y}, \text{ para algún } \mathbb{x} \in \RR[3] \right\} \\
        & = \left\{ \mathbb{y} \in \RR[4] \mid \begin{bmatrix}
            x - y \\
            y + z \\
            2x - y - z \\
            - x + y + 2z
        \end{bmatrix} = \mathbb{y}, \text{ para algún } \begin{pmatrix}
            x \\
            y \\
            z
        \end{pmatrix} \in \RR[3] \right\} \\
        & = \left\{ x \begin{pmatrix*}[r]
            1 \\
            0 \\
            2 \\
            -1
        \end{pmatrix*} + y \begin{pmatrix*}[r]
            -1 \\
            1 \\
            -1 \\
            1
        \end{pmatrix*} + z \begin{pmatrix*}[r]
            0 \\
            1 \\
            -1 \\
            2
        \end{pmatrix*} \mid x,  y,  z \in \RR \right\}
    \end{align*}
    Por tanto,
    $$\Ima(T) = \Gen \left( \left\{ \begin{pmatrix*}[r]
        1 \\
        0 \\
        2 \\
        -1
    \end{pmatrix*},  \begin{pmatrix*}[r]
        -1 \\
        1 \\
        -1 \\
        1
    \end{pmatrix*},  \begin{pmatrix*}[r]
        0 \\
        1 \\
        -1 \\
        2
    \end{pmatrix*} \right\} \right)$$
    y como son l.i, se sigue que $\rho(T) = 3$.
\end{example}

\begin{theorem}
    Dada $T:\RR[n] \longrightarrow \RR[m]$ y $A_T \in \matrizmn$ su representación matricial, entonces
    \begin{enumerate}[label=\roman*)]
        \item $\Nuc(T) = \Nuc(A_T)$.
        \item $\Ima(T) = \Ima(A_T)$.
        \item $\nu(T) = \nu(A_T)$.
        \item $\rho(T) = \rho(A_T)$.
    \end{enumerate}
\end{theorem}

\newpage

\section{Isomorfismos}

\begin{definition}
    Sea $T:V \longrightarrow W$ una transformación lineal. Decimos que $T$ es uno a uno si\infoBulle{Una transformación uno a uno se llama también inyectiva.}
    $$T\mathbb{u} = T\mathbb{v} \Longrightarrow \mathbb{u} = \mathbb{v}$$
    siendo $\mathbb{u}$, $\mathbb{v} \in V$. Equivalentemente, $T$ es uno a uno si
    $$T\mathbb{u} \neq T\mathbb{v} \Longrightarrow \mathbb{u} \neq \mathbb{v}$$
    siendo $\mathbb{u}$, $\mathbb{v} \in V$.
\end{definition}

\begin{theorem}\label{theo:nu_cero}
    Sea $T:V \longrightarrow W$ una transformación lineal, $T$ es uno a uno si y solo si
    $$\Nuc(T) = \{ \mathbb{0}_V \}$$
    \demostracion
    \begin{enumerate}
        \item[$\bm{\Rightarrow}$)] Supongamos que $T$ es uno a uno, hay que demostrar que
        $$\Nuc(T) = \{ \mathbb{0}_V \}$$
        Como $T$ es uno a uno, entonces
        \begin{equation}
            T\mathbb{u} = T\mathbb{v} \Longrightarrow \mathbb{u} = \mathbb{v}, \text{ para } \mathbb{u},  \mathbb{v} \in V \label{JAJJANNJBAJBABBGTQQH}
        \end{equation}
        De \eqref{JAJJANNJBAJBABBGTQQH},
        \begin{align*}
            \mathbb{0}_W & = T\mathbb{v} - T\mathbb{v} \\
            & = T\mathbb{u} - T\mathbb{v} \\
            & = T(\mathbb{u} - \mathbb{v})
        \end{align*}
        Por lo que $T(\mathbb{u} - \mathbb{v}) = \mathbb{0}_W$ de donde se sigue que $\mathbb{u} - \mathbb{v} \in \Nuc(T)$. Sea $\mathbb{v} \in \Nuc(T)$, entonces
        \begin{equation}
            T\mathbb{v} = \mathbb{0}_W \label{JAIAIJAKJJBJBA}
        \end{equation}
        Además,
        \begin{equation}
            T\mathbb{0}_V = \mathbb{0}_W \label{JAINNJJJAJJIA}
        \end{equation}
        De \eqref{JAIAIJAKJJBJBA} y \eqref{JAINNJJJAJJIA},
        $$T\mathbb{0}_V = T\mathbb{v}$$
        entonces $\mathbb{v} = \mathbb{0}$ por ser $T$ uno a uno. Por tanto, $\Nuc(T) = \{ \mathbb{0} \}$.
        \item[$\bm{\Leftarrow}$)] Supongamos que $\Nuc(T) = \{ \mathbb{0} \}$, hay que demostrar que $T$ es uno a uno. Sea
        $$T\mathbb{u} = T\mathbb{v}, \text{ con } \mathbb{u},  \mathbb{v} \in V$$
        Entonces
        \begin{align*}
            \mathbb{0}_W & = T\mathbb{v} - T\mathbb{v} \\
            & = T\mathbb{u} - T\mathbb{v} \\
            & = T(\mathbb{u} - \mathbb{v})
        \end{align*}
        entonces $\mathbb{u} - \mathbb{v} \in \Nuc(T) = \{ \mathbb{0} \}$. Así, $\mathbb{u} - \mathbb{v} = \mathbb{0}$; por lo tanto, $\mathbb{u} = \mathbb{v}$, lo que muestra que $T$ es uno a uno.
    \end{enumerate}
\end{theorem}

\begin{example}
    Verifique que la transformación lineal $T:\RR[2] \longrightarrow \RR[2]$, definida como sigue
    $$T \begin{pmatrix}
        x \\
        y
    \end{pmatrix} = \begin{pmatrix}
        x + y \\
        x - y
    \end{pmatrix}$$
    es uno a uno. \newpage
    \solucion Para determinar si $T$ es uno a uno, utilizaremos el teorema anterior. Por definición,
    \begin{align*}
        \Nuc(T) & = \left\{ \begin{pmatrix}
            x \\
            y
        \end{pmatrix} \in \RR[2] \mid T\begin{pmatrix}
            x \\
            y
        \end{pmatrix} = \begin{pmatrix}
            0 \\
            0
        \end{pmatrix} \right\} \\
        & = \left\{ \begin{pmatrix}
            x \\
            y
        \end{pmatrix} \in \RR[2] \mid \begin{pmatrix}
            x + y \\
            x - y
        \end{pmatrix} = \begin{pmatrix}
            0 \\
            0
        \end{pmatrix} \right\}
    \end{align*}
    lo cual, implica resolver el siguiente sistema
    \begin{align*}
        x + y & = 0 \\
        x - y & = 0
    \end{align*}
    donde la única solución es
    $$x = 0 \quad \text{ e } \quad y = 0$$
    Por lo tanto, $\displaystyle \Nuc(T) = \left\{ \begin{pmatrix}
        0 \\
        0
    \end{pmatrix} \right\}$, y dado el teorema anterior, $T$ es uno a uno.
\end{example}

\begin{example}
    Verifique que la transformación lineal $T:\RR[2] \longrightarrow \RR[2]$, definida como sigue
    $$T \begin{pmatrix}
        x \\
        y
    \end{pmatrix} = \begin{pmatrix}
        x + y \\
        x + y
    \end{pmatrix}$$
    no es uno a uno. \\
    \solucion Para determinar que $T$ no es uno a uno, utilizaremos el teorema anterior. Por definición,
    \begin{align*}
        \Nuc(T) & = \left\{ \begin{pmatrix}
            x \\
            y
        \end{pmatrix} \in \RR[2] \mid T\begin{pmatrix}
            x \\
            y
        \end{pmatrix} = \begin{pmatrix}
            0 \\
            0
        \end{pmatrix} \right\} \\
        & = \left\{ \begin{pmatrix}
            x \\
            y
        \end{pmatrix} \in \RR[2] \mid \begin{pmatrix}
            x + y \\
            x + y
        \end{pmatrix} = \begin{pmatrix}
            0 \\
            0
        \end{pmatrix} \right\}
    \end{align*}
    lo cual, implica resolver el siguiente sistema
    \begin{align*}
        x + y & = 0 \\
        x + y & = 0
    \end{align*}
    donde se reduce a la expresión
    $$y = - x$$
    Por lo tanto, $\displaystyle \Nuc(T) = \Gen \left( \left\{ \begin{pmatrix*}[r]
        1 \\
        -1
    \end{pmatrix*} \right\} \right) \neq \begin{pmatrix}
        0 \\
        0
    \end{pmatrix}$, y dado el teorema anterior, $T$ no es uno a uno.
\end{example}

\begin{example}\label{exam:tlmar4}
    Verifique que la transformación lineal $T:\mathcal{M}_{2 \times 2}(\RR) \longrightarrow \RR[4]$, definida como sigue
    $$T \begin{bmatrix}
        a & b \\
        c & d
    \end{bmatrix} = \begin{pmatrix}
        a \\
        b \\
        c \\
        d
    \end{pmatrix}$$
    es uno a uno. \\
    \solucion Al igual que los ejemplos anteriores, utilizaremos el teorema anterior. Por definición,
    \begin{align*}
        \Nuc(T) & = \left\{ \begin{bmatrix}
            a & b \\
            c & d
        \end{bmatrix} \in \mathcal{M}_{2 \times 2}(\RR) \mid T \begin{bmatrix}
            a & b \\
            c & d
        \end{bmatrix} = \begin{pmatrix}
            0 \\
            0 \\
            0 \\
            0
        \end{pmatrix} \right\} \\
        & = \left\{ \begin{bmatrix}
            a & b \\
            c & d
        \end{bmatrix} \in \mathcal{M}_{2 \times 2}(\RR) \mid \begin{pmatrix}
            a \\
            b \\
            c \\
            d
        \end{pmatrix} = \begin{pmatrix}
            0 \\
            0 \\
            0 \\
            0
        \end{pmatrix} \right\}
    \end{align*}\newpage\noindent
    lo cual implica que
    $$\begin{pmatrix}
        a \\
        b \\
        c \\
        d
    \end{pmatrix} = \begin{pmatrix}
        0 \\
        0 \\
        0 \\
        0
    \end{pmatrix}$$
    Por lo tanto, $\displaystyle \Nuc(T) = \left\{ \begin{pmatrix}
        0 \\
        0 \\
        0 \\
        0
    \end{pmatrix} \right\}$, y dado el teorema anterior, $T$ es uno a uno.
\end{example}

\begin{example}
    Sea $V = C^1(-\infty, \infty)$ el espacio vectorial de funciones con derivadas continuas de primer orden en $(-\infty, \infty)$, y sea $W = F(-\infty, \infty)$ el espacio vectorial de todas las funciones de valores reales definidas en $(-\infty, \infty)$. Sea $D: V \longrightarrow W$ la transformación que asigna a una función $f(x)$ su derivada, es decir,
    $$D_f = f'(x)$$
    A partir de las propiedades de la diferenciación, tenemos
    $$D(f + g) = D_f + D_g \quad \text{ y } \quad D(kf) = kD_f$$
    Esta transformación lineal no es uno a uno, ya que asigna funciones que difieren en una constante a la misma función. Por ejemplo,
    $$D(x^2) = 2x = D(x^2 + 1)$$
\end{example}

\begin{definition}
    Sea $T: V \longrightarrow W$ una transformación lineal. Entonces decimos que $T$ es sobre\infoBulle{Una transformación sobre se denomina también suprayectiva.}$W$ o simplemente sobre si para todo $\mathbb{w} \in W$ existe cuando menos $\mathbb{v} \in V$ tal que $T\mathbb{v} = \mathbb{w}$. Es decir, $T$ es sobre $W$ si y solo si $\Ima(T) = W$.
\end{definition}

Observemos que una transformación lineal $T:V \longrightarrow W$ se puede interpretar de acuerdo con lo que se muestra en las siguientes figuras:
\begin{figure*}[h!]
    \centering
    \subfloat[Uno a uno: Los vectores distintos en $V$ tienen imágenes distintas en $W$]{
    \begin{tikzpicture}
        %%%%% COORDENADAS %%%%%
        \coordinate (P1) {};
        \coordinate[above right=1.25cm and 1.25cm of P1] (P2) {};
        \coordinate[above=3cm of P2, label=above:$V$] (P3) {};
        \coordinate[below left=1.25cm and 1.25cm of P3] (P4);
        \def\dista{2.25cm}
        \coordinate[right=\dista of P1] (P11) {};
        \coordinate[right=\dista of P2] (P22) {};
        \coordinate[right=\dista of P3, label=above:$W$] (P33) {};
        \coordinate[right=\dista of P4] (P44) {};
        %
        \coordinate[above right=1cm and 0.4cm of P1] (V1);
        \coordinate[above right=1.5cm and 0.5cm of P1] (V2);
        \coordinate[above right=2.1cm and 0.7cm of P1] (V3);
        \coordinate[above right=2.7cm and 0.8cm of P1] (V4);
        \coordinate[above right=3.3cm and 1cm of P1] (V5);
        %%%%% V %%%%%
        \filldraw[gray,opacity=0.2] (P1) -- (P2) -- (P3) -- (P4) -- (P1) -- cycle;
        %%%%% PUNTOS Y FLECHAS %%%%%
        \foreach \i in {1,2,...,5} {
        \filldraw (V\i) circle (1.75pt);
        \coordinate[right=\dista of V\i] (W\i);
        \filldraw (W\i) circle (1.75pt);
        \draw[-Stealth, shorten >=4pt] (V\i) -- (W\i);
        }
        %%%%% W %%%%%
        \filldraw[gray,opacity=0.2] (P11) -- (P22) -- (P33) -- (P44) -- (P11) -- cycle;
    \end{tikzpicture}
    } \hfill
    \subfloat[No uno a uno: Existen vectores distintos en $V$ con la misma imagen]{
    \begin{tikzpicture}
        %%%%% COORDENADAS %%%%%
        \coordinate (P1) {};
        \coordinate[above right=1.25cm and 1.25cm of P1] (P2) {};
        \coordinate[above=3cm of P2, label=above:$V$] (P3) {};
        \coordinate[below left=1.25cm and 1.25cm of P3] (P4);
        \def\dista{2.25cm}
        \coordinate[right=\dista of P1] (P11) {};
        \coordinate[right=\dista of P2] (P22) {};
        \coordinate[right=\dista of P3, label=above:$W$] (P33) {};
        \coordinate[right=\dista of P4] (P44) {};
        %
        \coordinate[above right=1cm and 0.4cm of P1] (V1);
        \coordinate[above right=1.5cm and 0.5cm of P1] (V2);
        \coordinate[above right=2.1cm and 0.7cm of P1] (V3);
        \coordinate[above right=2.7cm and 0.8cm of P1] (V4);
        \coordinate[above right=3.3cm and 1cm of P1] (V5);
        %
        \coordinate[right=\dista of V1] (W1);
        \coordinate[right=\dista of V3] (W2);
        \coordinate[right=\dista of V4] (W3);
        %%%%% V %%%%%
        \filldraw[gray,opacity=0.2] (P1) -- (P2) -- (P3) -- (P4) -- (P1) -- cycle;
        %%%%% PUNTOS %%%%%
        \foreach \i in {1,2,...,5} 
        \filldraw (V\i) circle (1.75pt);
        \foreach \j in {1,2,3}
        \filldraw (W\j) circle (1.75pt);
        %%%%% FLECHAS %%%%%
        \draw[-Stealth, shorten >=4pt] (V1) -- (W1);
        \draw[-Stealth, shorten >=4pt] (V2) -- (W3);
        \draw[-Stealth, shorten >=4pt] (V3) -- (W2);
        \draw[-Stealth, shorten >=4pt] (V4) -- (W3);
        \draw[-Stealth, shorten >=4pt] (V5) -- (W2);
        %%%%% W %%%%%
        \filldraw[gray,opacity=0.2] (P11) -- (P22) -- (P33) -- (P44) -- (P11) -- cycle;
    \end{tikzpicture}
    } \hfill 
    \subfloat[Sobre: Cada vector en $W$ es la \\ imagen de algún vector en $V$]{
    \begin{tikzpicture}
        %%%%% COORDENADAS %%%%%
        \coordinate (P1) {};
        \coordinate[above right=1.25cm and 1.25cm of P1] (P2) {};
        \coordinate[above=3cm of P2, label=above:$V$] (P3) {};
        \coordinate[below left=1.25cm and 1.25cm of P3] (P4);
        \def\dista{2.25cm}
        \coordinate[right=\dista of P1] (X1);
        \coordinate[right=\dista of P2] (X2);
        \coordinate[right=\dista of P3, label=above:$W$] (X3);
        \coordinate[right=\dista of P4] (X4);
        \coordinate[above right=2cm and 3cm=of P1] (PP);
        %%%%% V %%%%%
        \filldraw[gray,opacity=0.2] (P1) -- (P2) -- (P3) -- (P4) -- (P1) -- cycle;
        %%%%% LÍNEAS %%%%%
        \foreach \i in {1,2,3,4}
        \draw[dash pattern=on 3pt off 3pt] (P\i) -- (X\i);
        %%%%% W %%%%%
        \filldraw[gray,opacity=0.4] (X1) -- (X2) -- (X3) -- (X4) -- (X1) -- cycle;
        \node[above right=0.01cm and 3cm of P1, font=\footnotesize] (C) {\makecell{Rango \\ de $T$}};
        \draw[-latex] (C) .. controls ($(C)!.65!(PP) + (0.5,0)$) and ($(C)!.65!(PP) + (0,0.5)$) .. (PP);
    \end{tikzpicture}
    } \hfill 
    \subfloat[No sobre: No todos los vectores en $W$ son la imagen de algún vector en $V$]{
    \begin{tikzpicture}
        %%%%% COORDENADAS %%%%%
        \coordinate (P1) {};
        \coordinate[above right=1.25cm and 1.25cm of P1] (P2) {};
        \coordinate[above=3cm of P2, label=above:$V$] (P3) {};
        \coordinate[below left=1.25cm and 1.25cm of P3] (P4);
        \def\dista{2.25cm}
        \coordinate[right=\dista of P1] (X1);
        \coordinate[right=\dista of P2] (X2);
        \coordinate[right=\dista of P3, label=above:$W$] (X3);
        \coordinate[right=\dista of P4] (X4);
        \coordinate (Y1) at ($(X1)!.25!(X3)$);
        \coordinate (Y2) at ($(X2)!.25!(X4)$);
        \coordinate (Y3) at ($(X1)!.75!(X3)$);
        \coordinate (Y4) at ($(X2)!.75!(X4)$);
        \coordinate[above right=2cm and 3cm=of P1] (PP);
        %%%%% V %%%%%
        \filldraw[gray,opacity=0.2] (P1) -- (P2) -- (P3) -- (P4) -- (P1) -- cycle;
        %%%%% LÍNEAS %%%%%
        \foreach \i in {1,2,3,4}
        \draw[dash pattern=on 3pt off 3pt] (P\i) -- (Y\i);
        %%%%% W %%%%%
        \filldraw[gray,opacity=0.2] (X1) -- (X2) -- (X3) -- (X4) -- (X1) -- cycle;
        \filldraw[gray,opacity=0.4] (Y1) -- (Y2) -- (Y3) -- (Y4) -- (Y1) -- cycle;
        \node[above right=0.01cm and 3cm of P1, font=\footnotesize] (C) {\makecell{Rango \\ de $T$}};
        \draw[-latex] (C) .. controls ($(C)!.65!(PP) + (0.5,0)$) and ($(C)!.65!(PP) + (0,0.5)$) .. (PP);
    \end{tikzpicture}
    }
\end{figure*}

\begin{definition}
    Sea $T:V \longrightarrow W$ una transformación lineal. Decimos que $T$ es un isomorfismo si $T$ es uno a uno y sobre.
\end{definition}

\begin{definition}
    Se dice que los espacios vectoriales $V$ y $W$ son isomorfos si existe un isomorfismo $T$ de $V$ sobre $W$. En este caso, se escribe $V \cong W$.
\end{definition}

\begin{theorem}\label{theo:unoauno-sobre}
    Sean $V$ y $W$ dos espacios vectoriales de dimensión finita con la misma dimensión, digamos $n$, es decir, $\Dim V = n = \Dim W$. Consideremos $T: V \longrightarrow W$ una transformación lineal,\newpage
    \begin{enumerate}[label=\roman*)]
        \item Si $T$ es uno a uno, entonces $T$ es sobre.
        \item Si $T$ es sobre, entonces $T$ es uno a uno.
    \end{enumerate}
    \demostracion
    \begin{enumerate}[label=\roman*)]
        \item Sea $T$ uno a uno. Como $\Dim(V) = n$, entonces $\{ \mathbb{v}_1,  \mathbb{v}_2,  \dots,  \mathbb{v}_n \}$ es una base de $V$. Ahora
        $$T\mathbb{v}_i = \mathbb{w}_i, \text{ para } i = 1, 2, \dots, n$$
        Además, $\mathbb{w}_i = T\mathbb{v}_i \neq T\mathbb{v}_j = \mathbb{w}_j$, donde se sigue que $\mathbb{v}_i \neq \mathbb{v}_j$, puesto que $T$ es uno a uno. Ahora, $\{ \mathbb{w}_1, \mathbb{w}_2, \dots,  \mathbb{w}_n \}$ es una base de $W$, veamos que son l.i, es decir, para $b_i \in K$
        \begin{align*}
            \mathbb{0}_W & = b_1\mathbb{w}_1 + b_2\mathbb{w}_2 + \cdots + b_n \mathbb{w}_n \\
            & = b_1T\mathbb{v}_1 + b_2T\mathbb{v}_2 + \cdots + b_nT\mathbb{v}_n \\
            & = T(b_1\mathbb{v}_1) + T(b_2\mathbb{v}_2) + \cdots + T(b_n\mathbb{v}_n) \\
            & = T(b_1\mathbb{v}_1 + b_2\mathbb{v}_2 + \cdots + b_n\mathbb{v}_n)
        \end{align*}
        entonces $b_1\mathbb{v}_1 + b_2\mathbb{v}_2 + \cdots + b_n\mathbb{v}_n \in \Nuc(T)$. Como $T$ es uno a uno, por el teorema anterior, $\Nuc(T) = \{ \mathbb{0}_V \}$; por lo que
        $$\mathbb{0}_V = b_1\mathbb{v}_1 + b_2\mathbb{v}_2 + \cdots + b_n\mathbb{v}_n$$
        entonces $b_1 = 0$, $b_2 = 0$, $\dots$, $b_n = 0$ ya que $\{ \mathbb{v}_1,  \mathbb{v}_2,  \dots,  \mathbb{v}_n \}$ es una base de $V$. Por tanto, $\mathbb{w}_1,  \mathbb{w}_2,  \dots,  \mathbb{w}_n$ son l.i. Sea $\mathbb{w} \in W$ arbitraria, entonces
        \begin{equation}
            \mathbb{w} = \alpha_1 \mathbb{w}_1 + \alpha_2 \mathbb{w}_2 + \cdots + \alpha_n \mathbb{w}_n \label{JHDFHGBSDHFGHDSGFHGH}
        \end{equation}
        siendo $\alpha_i \in K$ para $i = 1,  2,  \dots,  n$ y $\{ \mathbb{w}_1,  \mathbb{w}_2,  \dots, \mathbb{w}_n \}$ una base de $W$. Como $T\mathbb{v}_i = \mathbb{w}_i$, para $i = 1,  2,  \dots,  n$, entonces de \eqref{JHDFHGBSDHFGHDSGFHGH} se sigue que
        \begin{align*}
            \mathbb{w} & = \alpha_1T\mathbb{v}_1 + \alpha_2T\mathbb{v}_2 + \cdots + \alpha_nT\mathbb{v}_n \\
            & = T(\alpha_1\mathbb{v}_1) + T(\alpha_2\mathbb{v}_2) + \cdots + T(\alpha_n\mathbb{v}_n) \\
            & = T(\alpha_1\mathbb{v}_1 + \alpha_2\mathbb{v}_2 + \cdots + \alpha_n\mathbb{v}_n) \\
            & = T\mathbb{v}
        \end{align*}
        siendo
        $$\mathbb{v} = \alpha_1\mathbb{v}_1 + \alpha_2\mathbb{v}_2 + \cdots + \alpha_n\mathbb{v}_n \in V$$
        Esto es, dado $\mathbb{w} \in W$, existe al menos un $\mathbb{v} \in V$ tal que $T\mathbb{v} = \mathbb{w}$, es decir, $T$ es sobre.
        \item Se deja como ejercicio al lector.
    \end{enumerate}
\end{theorem}

\begin{example}
    Si consideramos los espacios vectoriales $V = \mathcal{M}_{2 \times 2}(\RR)$ y $W = \RR[4]$, notemos que ambos espacios vectoriales tienen la misma dimensión, es decir, $\Dim \mathcal{M}_{2 \times 2}(\RR)= 4 = \Dim \RR[4]$. Sea $T$ definida como en el ejemplo \ref{exam:tlmar4}:
    $$T \begin{bmatrix}
        a & b \\
        c & d
    \end{bmatrix} = \begin{pmatrix}
        a \\
        b \\
        c \\
        d
    \end{pmatrix}$$
    Se sigue del teorema anterior que $T$ es un isomorfismo entre $\mathcal{M}_{2 \times 2}(\RR)$ y $\RR[4]$, pues en el ejemplo \ref{exam:tlmar4} se probó que $T$ es uno a uno, lo cual implica que $T$ es sobre. Este es un caso especial del isomorfismo que asigna una matriz $m \times n$ a un vector de $mn \times 1$. A esto lo llamamos el \emph{isomorfismo natural entre $\mathcal{M}_{m \times n}(\RR)$ y $\RR[mn]$}.
\end{example}

\newpage

\begin{example}
    Si consideramos los espacios vectoriales $V = P_{n-1}(x)$ y $W = \RR[n]$, notemos que ambos espacios vectoriales tienen la misma dimensión, es decir, $\Dim P_{n-1}(x) = n = \Dim \RR[n]$. Sea $T: P_{n-1}(x) \longrightarrow \RR[n]$ definida como
    $$T(a_0 + a_1 + \cdots + a_{n-1}x^{n-1}) = \begin{pmatrix} a_0 \\ a_1 \\ \vdots \\ a_{n-1} \end{pmatrix}$$
    Es fácil probar que $T$ es uno a uno, pues si $\mathbb{p} = a_0 + a_1 + \cdots + a_{n-1}x^{n-1}$, entonces por definición
    $$\Nuc(T) = \left\{ \mathbb{p} \in P_{n-1}(x) \mid T(\mathbb{p}) = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 0 \end{pmatrix} \right\}$$
    lo cual implica que
    $$\begin{pmatrix}
        a_0 \\
        a_1 \\
        \vdots \\
        a_{n-1}
    \end{pmatrix} = \begin{pmatrix}
        0 \\
        0 \\
        \vdots \\
        0
    \end{pmatrix}$$
    Por lo tanto, $\displaystyle \Nuc(T) = \left\{ \begin{pmatrix}
        0 \\
        0 \\
        \vdots \\
        0
    \end{pmatrix} \right\}$, y dado el teorema \ref{theo:nu_cero}, $T$ es uno a uno. Se sigue del teorema anterior que $T$ es un isomorfismo entre $P_{n-1}(x)$ y $\RR[n]$, pues se probó que $T$ es uno a uno, lo cual implica que $T$ es sobre. A esto lo llamamos el \emph{isomorfismo natural entre $P_{n-1}(x)$ y $\RR[n]$}.
\end{example}

\begin{example}
    Consideremos la transformación de diferenciación dada por $D: P_3(x) \longrightarrow P_2(x)$ en el espacio vectorial de polinomios de grado $3$ o menor. Si mapeamos $P_3(x)$ y $P_2(x)$ en $\RR[4]$ y $\RR[3]$, respectivamente, mediante los isomorfismos naturales, entonces la transformación $D$ produce una transformación matricial correspondiente de $\RR[4]$ a $\RR[3]$. Específicamente, la transformación de diferenciación
    $$D(a_0 + a_1x + a_2x^2 + a_3x^3) = a_1 + 2a_2x + 3a_3x^2$$
    produce la transformación matricial
    $$\begin{bmatrix}
        0 & 1 & 0 & 0 \\
        0 & 0 & 2 & 0 \\
        0 & 0 & 0 & 3
    \end{bmatrix}\begin{bmatrix}
        a_0 \\
        a_1 \\
        a_2 \\
        a_3
    \end{bmatrix} = \begin{bmatrix}
        a_1 \\
        2a_2 \\
        3a_3
    \end{bmatrix}$$
    Así, por ejemplo, la derivada
    $$\frac{d}{dx}(2 + x + 4x^2 - x^3) = 1 + 8x - 3x^2$$
    se puede calcular como el producto matricial
    $$\begin{bmatrix}
        0 & 1 & 0 & 0 \\
        0 & 0 & 2 & 0 \\
        0 & 0 & 0 & 3
    \end{bmatrix}\begin{bmatrix*}[r]
        2 \\
        1 \\
        4 \\
        -1
    \end{bmatrix*} = \begin{bmatrix*}[r]
        1 \\
        8 \\
        -3
    \end{bmatrix*}$$
    Esta idea es útil para construir algoritmos numéricos para calcular derivadas.
\end{example}

\newpage

\section{Composición y transformación inversa}

\infoBulle{Observe que la palabra “con” establece el orden de las operaciones en una composición. La composición de $T_2$ con $T_1$ está dada por
$$(T_2 \circ T_1)(\mathbb{u}) = T_2 \big(T_1(\mathbb{u})\big)$$
mientras que la composición de $T_1$ con $T_2$ está dada por
$$(T_1 \circ T_2)(\mathbb{u}) = T_1 \big(T_2(\mathbb{u})\big)$$
En general, no es cierto que
$$T_1 \circ T_2 = T_2 \circ T_1$$}

\begin{definition}
    Si $T_1: U \longrightarrow V$ y $T_2: V \longrightarrow W$ son transformaciones lineales, entonces la composición de $T_2$ con $T_1$, denotada por $T_2 \circ T_1$ (que se lee como “$T_2$ composición $T_1$”), es la función definida como
    $$(T_2 \circ T_1)(\mathbb{u}) = T_2\big(T_1(\mathbb{u})\big), \quad \text{ con } \mathbb{u} \in U$$
\end{definition}

Observe que esta definición requiere que el dominio de $T_2$ (que es $V$) contenga la imagen de $T_1$. Esto es esencial para que la expresión $T_2\big(T_1(\mathbb{u})\big)$ tenga sentido. La siguiente figura ilustra lo dicho anteriormente:
\begin{center}
    \begin{tikzpicture}
        %%%%% COORDENADAS %%%%%
        \coordinate[label=below left:$U$] (U1) {};
        \coordinate[right=2cm of U1] (U2);
        \coordinate[above right=1.2cm and 0.25cm of U2] (U3);
        \coordinate[left=2cm of U3] (U4);
        %
        \def\dista{4cm}
        \coordinate[right=\dista of U1, label=below left:$V$] (V1);
        \coordinate[right=\dista of U2] (V2);
        \coordinate[right=\dista of U3] (V3);
        \coordinate[right=\dista of U4] (V4);
        %
        \coordinate[right=\dista of V1, label=below left:$W$] (W1);
        \coordinate[right=\dista of V2] (W2);
        \coordinate[right=\dista of V3] (W3);
        \coordinate[right=\dista of V4] (W4);
        %
        \coordinate[above right=0.6cm and 1.125cm of U1] (U);
        \coordinate[right=\dista of U] (V);
        \coordinate[right=\dista of V] (W);
        %%%%% ESPACIOS VEC. %%%%%
        \filldraw[gray,opacity=0.2] (U1) -- (U2) -- (U3) -- (U4) -- (U1) -- cycle;
        \filldraw[gray,opacity=0.2] (V1) -- (V2) -- (V3) -- (V4) -- (V1) -- cycle;
        \filldraw[gray,opacity=0.2] (W1) -- (W2) -- (W3) -- (W4) -- (W1) -- cycle;
        %%%%% LETRAS %%%%%
        \filldraw (U) circle (1.75pt) node[below] {$\mathbb{u}$};
        \filldraw (V) circle (1.75pt) node[below] {$T_1(\mathbb{u})$};
        \filldraw (W) circle (1.75pt) node[below] {$T_2\big(T_1(\mathbb{u})\big)$};
        %%%%% FLECHAS %%%%%
        \draw[-Stealth, shorten >=4pt] (U) .. controls ($(U)!.3!(V) + (0,0.5)$) and ($(U)!.7!(V) + (0,0.5)$) .. node[midway, below] {$T_1$} (V);
        \draw[-Stealth, shorten >=4pt] (V) .. controls ($(V)!.3!(W) + (0,0.5)$) and ($(V)!.7!(W) + (0,0.5)$) .. node[midway, below] {$T_2$} (W);
        \draw[-Stealth, shorten >=4pt] (U) .. controls ($(U)!.3!(W) + (0,1.25)$) and ($(U)!.7!(W) + (0,1.25)$) .. node[midway, above] {$T_2 \circ T_1$} (W);
    \end{tikzpicture}
\end{center}

Nuestro siguiente teorema muestra que la composición de dos transformaciones lineales es en sí misma una transformación lineal.

\begin{theorem}
    Si $T_1: U \longrightarrow V$ y $T_2: V \longrightarrow W$ son transformaciones lineales, entonces $(T_2 \circ T_1): U \longrightarrow W$ también es una transformación lineal. \\
    \demostracion Si $\mathbb{u}$ y $\mathbb{v}$ son vectores en $U$ y $c$ es un escalar, entonces se deduce de la definición de composición y de la linealidad de $T_1$ y $T_2$ que
    \begin{align*}
        (T_2 \circ T_1)(\mathbb{u} + \mathbb{v}) & = T_2\big(T_1(\mathbb{u} + \mathbb{v})\big) \\
        & = T_2\big(T_1(\mathbb{u}) + T_1(\mathbb{v})\big) \\
        & = T_2\big(T_1(\mathbb{u})\big) + T_2\big(T_1(\mathbb{v})\big) \\
        & = (T_2 \circ T_1)(\mathbb{u}) + (T_2 \circ T_1)(\mathbb{v})
    \end{align*}
    y
    \begin{align*}
        (T_2 \circ T_1)(c\mathbb{u}) & =T_2\big(T_1(c\mathbb{u})\big) \\
        & = T_2\big(cT_1(\mathbb{u})\big) \\
        & = cT_2\big(T_1(\mathbb{u})\big) \\
        & = c(T_2 \circ T_1)(\mathbb{u})
    \end{align*}
    Ya que $T_2 \circ T_1$ satisface las dos condiciones de una transformación lineal, se sigue que $T_2 \circ T_1$ es una transformación lineal.
\end{theorem}

\begin{example}
    Sean $T_1: P_1 \longrightarrow P_2$ y $T_2: P_2 \longrightarrow P_2$ transformaciones lineales dadas por las fórmulas
    $$T_1\big(p(x)\big) = xp(x) \quad \text{ y } \quad T_2\big(p(x)\big) = p(2x + 4)$$
    Entonces la composición $(T_2 \circ T_1): P_1 \longrightarrow P_2$ está dada por la fórmula
    $$(T_2 \circ T_1)\big(p(x)\big) = T_2\big(T_1(p(x))\big) = T_2\big(xp(x)\big) = (2x + 4)p(2x + 4)$$
    En particular, si $p(x) = c_0 + c_1x$, entonces
    \begin{align*}
        (T_2 \circ T_1)\big(p(x)\big) & = (T_2 \circ T_1)(c_0 + c_1x) \\
        & = (2x + 4)\big(c_0 + c_1(2x + 4)\big) \\
        & = c_0(2x + 4) + c_1(2x + 4)^2
    \end{align*}
\end{example}

\newpage

\begin{example}
    Si $T: V \longrightarrow V$ es un operador lineal y $I: V \longrightarrow V$ es el operador identidad, entonces para cualquier vector $\mathbb{v} \in V$, se cumple que
    \begin{align*}
        (T \circ I)(\mathbb{v}) = T\big(I(\mathbb{v})\big) = T(\mathbb{v}) \\
        (I \circ T)(\mathbb{v}) = I\big(T(\mathbb{v})\big) = T(\mathbb{v})
    \end{align*}
    De esto se deduce que $T \circ I$ e $I \circ T$ son lo mismo que $T$, es decir
    $$T \circ I = T \quad \text{ e } \quad I \circ T = T$$
\end{example}

Como se ilustra en la siguiente figura, las composiciones pueden definirse para más de dos transformaciones lineales.
\begin{center}
    \begin{tikzpicture}
        %%%%% COORDENADAS %%%%%
        \coordinate[label=below left:$U$] (U1) {};
        \coordinate[right=2cm of U1] (U2);
        \coordinate[above right=1.2cm and 0.25cm of U2] (U3);
        \coordinate[left=2cm of U3] (U4);
        %
        \def\dista{2.9cm}
        \coordinate[right=\dista of U1, label=below left:$V$] (V1);
        \coordinate[right=\dista of U2] (V2);
        \coordinate[right=\dista of U3] (V3);
        \coordinate[right=\dista of U4] (V4);
        %
        \coordinate[right=\dista of V1, label=below left:$W$] (W1);
        \coordinate[right=\dista of V2] (W2);
        \coordinate[right=\dista of V3] (W3);
        \coordinate[right=\dista of V4] (W4);
        %
        \coordinate[right=\dista of W1, label=below left:$Y$] (Y1);
        \coordinate[right=\dista of W2] (Y2);
        \coordinate[right=\dista of W3] (Y3);
        \coordinate[right=\dista of W4] (Y4);
        %
        \coordinate[above right=0.6cm and 1.125cm of U1] (U);
        \coordinate[right=\dista of U] (V);
        \coordinate[right=\dista of V] (W);
        \coordinate[right=\dista of W] (Y);
        %%%%% ESPACIOS VEC. %%%%%
        \filldraw[gray,opacity=0.2] (U1) -- (U2) -- (U3) -- (U4) -- (U1) -- cycle;
        \filldraw[gray,opacity=0.2] (V1) -- (V2) -- (V3) -- (V4) -- (V1) -- cycle;
        \filldraw[gray,opacity=0.2] (W1) -- (W2) -- (W3) -- (W4) -- (W1) -- cycle;
        \filldraw[gray,opacity=0.2] (Y1) -- (Y2) -- (Y3) -- (Y4) -- (Y1) -- cycle;
        %%%%% LETRAS %%%%%
        \filldraw (U) circle (1.75pt) node[below] {$\mathbb{u}$};
        \filldraw (V) circle (1.75pt) node[below] {$T_1(\mathbb{u})$};
        \filldraw (W) circle (1.75pt) node[below] {$T_2\big(T_1(\mathbb{u})\big)$};
        \filldraw (Y) circle (1.75pt) node[below] {$T_3\big(T_2(T_1(\mathbb{u}))\big)$};
        %%%%% FLECHAS %%%%%
        \draw[-Stealth, shorten >=4pt] (U) .. controls ($(U)!.3!(V) + (0,0.5)$) and ($(U)!.7!(V) + (0,0.5)$) .. node[midway, below] {$T_1$} (V);
        \draw[-Stealth, shorten >=4pt] (V) .. controls ($(V)!.3!(W) + (0,0.5)$) and ($(V)!.7!(W) + (0,0.5)$) .. node[midway, below] {$T_2$} (W);
        \draw[-Stealth, shorten >=4pt] (W) .. controls ($(W)!.3!(Y) + (0,0.5)$) and ($(W)!.7!(Y) + (0,0.5)$) .. node[midway, below] {$T_3$} (Y);
        \draw[-Stealth, shorten >=4pt] (U) .. controls ($(U)!.3!(Y) + (0,1.5)$) and ($(U)!.7!(Y) + (0,1.5)$) .. node[midway, above] {$T_3 \circ T_2 \circ T_1$} (Y);
    \end{tikzpicture}
\end{center}
Por ejemplo, si $T_1: U \longrightarrow V$, $T_2: V \longrightarrow W$ y $T_3: W \longrightarrow Y$ son transformaciones lineales, entonces la composición $T_3 \circ T_2 \circ T_1$ se define como
$$(T_3 \circ T_2 \circ T_1)(\mathbb{u}) = T_3\big(T_2(T_1(\mathbb{u}))\big)$$

Si $T: V \longrightarrow W$ es una transformación lineal uno a uno con rango $\rho(T)$, y si $\mathbb{w}$ es un vector cualquiera en $\rho(T)$, el hecho de que $T$ sea uno a uno significa que existe exactamente un vector $\mathbb{v} \in V$ para el cual $T(\mathbb{v}) = \mathbb{w}$. Este hecho nos permite definir una nueva función, llamada la inversa de $T$ (y denotada por $T^{-1}$), que está definida en el rango de $T$ y que asigna $\mathbb{w}$ de vuelta a $\mathbb{v}$.
\begin{center}
    \begin{tikzpicture}
        %%%%% COORDENADAS %%%%%
        \coordinate[label=below left:$V$] (U1) {};
        \coordinate[right=2cm of U1] (U2);
        \coordinate[above right=1.2cm and 0.25cm of U2] (U3);
        \coordinate[left=2cm of U3] (U4);
        %
        \def\dista{4cm}
        \coordinate[right=\dista of U1] (V1);
        \coordinate[right=\dista of U2, label=below right:$\rho(T)$] (V2);
        \coordinate[right=\dista of U3] (V3);
        \coordinate[right=\dista of U4] (V4);
        %
        \coordinate[above right=0.6cm and 1.125cm of U1] (U);
        \coordinate[right=\dista of U] (V);
        %%%%% ESPACIOS VEC. %%%%%
        \filldraw[gray,opacity=0.2] (U1) -- (U2) -- (U3) -- (U4) -- (U1) -- cycle;
        \filldraw[gray,opacity=0.2] (V1) -- (V2) -- (V3) -- (V4) -- (V1) -- cycle;
        %%%%% LETRAS %%%%%
        \filldraw (U) circle (1.75pt) node[left] {$\mathbb{v}$};
        \filldraw (V) circle (1.75pt) node[right] {$\mathbb{w} = T(\mathbb{v})$};
        %%%%% FLECHAS %%%%%
        \draw[-Stealth, shorten >=4pt] (U) .. controls ($(U)!.3!(V) + (0,0.5)$) and ($(U)!.7!(V) + (0,0.5)$) .. node[midway, above] {$T$} (V);
        \draw[-Stealth, shorten >=4pt] (V) .. controls ($(V)!.3!(U) + (0,-0.5)$) and ($(V)!.7!(U) + (0,-0.5)$) .. node[midway, below] {$T^{-1}$} (U);
    \end{tikzpicture}
\end{center}

A continuación, vamos a demostrar que $T^{-1}: \rho(T) \longrightarrow V$ es una transformación lineal. Además, de la definición de $T^{-1}$ se obtiene que
\begin{equation}
    T^{-1}\big(T(\mathbb{v})\big) = T^{-1}(\mathbb{w}) = \mathbb{v} \label{JAJAIIAIAIQIOOCQJQ}
\end{equation}
y
\begin{equation}
    T\big(T^{-1}(\mathbb{w})\big) = T(\mathbb{v}) = \mathbb{w}
\end{equation}
Por lo tanto, $T$ y $T^{-1}$, cuando se aplican sucesivamente en cualquier orden, se anulan mutuamente.

\begin{theorem}
    Si $T: V \longrightarrow W$ es una transformación lineal uno a uno, entonces $T^{-1}: \rho(T) \longrightarrow V$ también es una transformación lineal uno a uno. \\
    \demostracion Sea $T: V \longrightarrow W$ una transformación lineal uno a uno. Entonces, para cada $\mathbb{w} \in \rho(T)$, existe un único $\mathbb{v} \in V$ tal que $T(\mathbb{v}) = \mathbb{w}$. Así, la función $T^{-1}: \rho(T) \longrightarrow V$, que asigna a cada $\mathbb{w} \in \rho(T)$ el único $\mathbb{v}$ tal que $T(\mathbb{v}) = \mathbb{w}$, está bien definida, y este $\mathbb{v}$ se denota por $T^{-1}(\mathbb{w})$. Ahora, dado $\mathbb{v} \in V$, si definimos $\mathbb{w} = T(\mathbb{v})$, entonces, dado que $T$ es uno a uno, $\mathbb{v}$ es el único vector en $V$ tal que $T(\mathbb{v}) = \mathbb{w}$. De este modo, $T^{-1}(\mathbb{w}) = T^{-1}\big(T(\mathbb{v})\big) = \mathbb{v}$. Para $\mathbb{w} \in \rho(T)$, como $\mathbb{v} = T^{-1}(\mathbb{w})$ es el único vector en $V$ tal que $T(\mathbb{v}) = \mathbb{w}$, se sigue que $T\big(T^{-1}(\mathbb{w})\big) = \mathbb{w}$. Por lo tanto,
    $$T^{-1}\big(T(\mathbb{v})\big) = \mathbb{v}, \forall \mathbb{v} \in V \quad \text{ y } T\big(T^{-1}(\mathbb{w})\big) = \mathbb{w}, \forall \mathbb{w} \in \rho(T)$$
    Dado que $T$ es uno a uno, para $\mathbb{w}_1, \mathbb{w}_2 \in \rho(T)$ existen únicos $\mathbb{v}_1, \mathbb{v}_2 \in V$ tales que
    $$T(\mathbb{v}_1) = \mathbb{w}_1 \quad \text{ y } \quad T(\mathbb{v}_2) = \mathbb{w}_2.$$
    Entonces,
    \begin{align*}
        T^{-1}(\mathbb{w}_1 + \mathbb{w}_2) & = T^{-1}\big(T(\mathbb{v}_1) + T(\mathbb{v}_2)\big) \\
        & = T^{-1}\big(T(\mathbb{v}_1 + \mathbb{v}_2)\big) \\
        & = \mathbb{v}_1 + \mathbb{v}_2 \\
        & = T^{-1}\big(T(\mathbb{v}_1)\big) + T^{-1}\big(T(\mathbb{v}_2)\big) \\
        & = T^{-1}(\mathbb{w}_1) + T^{-1}(\mathbb{w}_2).
    \end{align*}
    Además, para $\mathbb{w} \in \rho(T)$, existe un único $\mathbb{v} \in V$ tal que $T(\mathbb{v}) = \mathbb{w}$, lo que implica que para cualquier escalar $k$ se tiene:
    \begin{align*}
        T^{-1}(k\mathbb{w}) & = T^{-1}\big(kT(\mathbb{v})\big) \\
        & = T^{-1}\big(T(k\mathbb{v})\big) \\
        & = k\mathbb{v} \\
        & = kT^{-1}\big(T(\mathbb{v})\big) \\
        & = kT^{-1}(\mathbb{w}).
    \end{align*}
    Por lo tanto, $T^{-1}$ es una transformación lineal. 

    Finalmente, consideremos $\mathbb{w} \in \Nuc(T^{-1})$. Si $T^{-1}(\mathbb{w}) = \mathbb{0}_V$, aplicando $T$ obtenemos $T\big(T^{-1}(\mathbb{w})\big) = T(\mathbb{0}_V)$. Como $T\big(T^{-1}(\mathbb{w})\big) = \mathbb{w}$ y $T(\mathbb{0}_V) = \mathbb{0}_W$, se deduce que $\mathbb{w} = \mathbb{0}_W$. Así, $\Nuc(T^{-1}) = \{\mathbb{0}_W\}$, y según el teorema \ref{theo:nu_cero}, $T^{-1}$ es uno a uno.
\end{theorem}

\begin{example}
    Dado $T: \RR[3] \longrightarrow \RR[3]$ el operador lineal definido por la fórmula
    $$T\begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} 3x_1 + x_2 \\ -2x_1 - 4x_2 + 3x_3 \\ 5x_1 + 4x_2 - 2x_3 \end{pmatrix}$$
    determine si $T$ es uno a uno; si es así, encuentre $T^{-1}$. \\
    \solucion Para probar que $T$ es uno a uno, debemos probar que $T(\mathbb{x}) = \mathbb{0}_{\RR[3]}$. Esto nos lleva a resolver el siguiente sistema
    \begin{align*}
        3x_1 + x_2 & = 0 \\
        -2x_1 - 4x_2 + 3x_3 & = 0 \\
        5x_1 + 4x_2 - 2x_3 & = 0
    \end{align*}
    Aplicando el método de reducción de Gauss-Jordan, obtenemos que el sistema tiene solución única y $x_1 = x_2 = x_3 = 0$. Por lo tanto, $T$ es uno a uno. Se sigue del teorema \ref{matrix_representationtl} que la representación matricial de $T$ es
    $$A_T = \begin{bmatrix*}[r]
        3 & 1 & 0 \\
        -2 & -4 & 3 \\
        5 & 4 & -2
    \end{bmatrix*}$$
    Usando el teorema \ref{singular_determinante}, tenemos que $\Det(A_T) = -1$ y, por lo tanto, $A_T$ es invertible. De esta forma, encontrando la inversa de $A_T$ tenemos que
    $$A^{-1}_T = \begin{bmatrix*}[r]
        4 & -2 & -3 \\
        -11 & 6 & 9 \\
        -12 & 7 & 10
    \end{bmatrix*}$$\newpage\noindent
    de donde se sigue que
    $$T^{-1}\begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} 4x_1 - 2x_2 - 3x_3 \\ -11x_1 + 6x_2 + 9x_3 \\ -12x_1 + 7x_2 + 10x_3 \end{pmatrix}$$
\end{example}

Concluimos esta sección con un teorema que muestra que la composición de transformaciones lineales uno a uno también es uno a uno, y que el inverso de una composición es la composición de los inversos en el orden inverso.

\begin{theorem}
    Si $T_1: U \longrightarrow V$ y $T_2: V \longrightarrow W$ son transformaciones lineales uno a uno, entonces:
    \begin{enumerate}[label=\alph*)]
        \item $T_2 \circ T_1$ es uno a uno.
        \item $(T_2 \circ T_1)^{-1} = T_1^{-1} \circ T_2^{-1}$.
    \end{enumerate}
    \demostracion
    \begin{enumerate}[label=\alph*)]
        \item Queremos demostrar que $T_2 \circ T_1$ mapea vectores distintos en $U$ en vectores distintos en $W$. Pero si $\mathbb{u}$ y $\mathbb{v}$ son vectores distintos en $U$, entonces $T_1(\mathbb{u})$ y $T_1(\mathbb{v})$ son vectores distintos en $V$ ya que $T_1$ es uno a uno. Esto, junto con el hecho de que $T_2$ es uno a uno, implica que
        $$T_2\big(T_1(\mathbb{u})\big) \quad \text{ y } \quad T_2\big(T_1(\mathbb{v})\big)$$
        también son vectores distintos. Pero estas expresiones también pueden escribirse como
        $$(T_2 \circ T_1)(\mathbb{u}) \quad \text{ y } \quad (T_2 \circ T_1)(\mathbb{v})$$
        Por lo tanto, $T_2 \circ T_1$ mapea $\mathbb{u}$ y $\mathbb{v}$ en vectores distintos en $W$.
        \item Queremos demostrar que
        $$(T_2 \circ T_1)^{-1}(\mathbb{w}) = (T_1^{-1} \circ T_2^{-1})(\mathbb{w})$$
        para cada vector $\mathbb{w}$ en la imagen de $T_2 \circ T_1$. Para este propósito, sea
        \begin{equation}
            \mathbb{u} = (T_2 \circ T_1)^{-1}(\mathbb{w}) \label{IAIOPAPAIUVCGQ}
        \end{equation}
        por lo que nuestro objetivo es demostrar que
        $$\mathbb{u} = (T_1^{-1} \circ T_2^{-1})(\mathbb{w})$$
        Pero se sigue de \eqref{IAIOPAPAIUVCGQ} que
        $$T_2\big(T_1(\mathbb{u})\big) = \mathbb{w}$$
        o de manera equivalente,
        $$(T_2 \circ T_1)(\mathbb{u}) = \mathbb{w}$$
        Ahora, al aplicar $T_1^{-1}$ en ambos lados de esta ecuación y luego $T_2^{-1}$ en ambos lados del resultado, y usando \eqref{JAJAIIAIAIQIOOCQJQ}, se obtiene que
        $$\mathbb{u} = T_1^{-1}\big(T_2^{-1}(\mathbb{w})\big)$$
        o de manera equivalente,
        $$\mathbb{u} = (T_1^{-1} \circ T_2^{-1})(\mathbb{w})$$
    \end{enumerate}
\end{theorem}

En otras palabras, la parte (b) del teorema anterior establece que la inversa de una composición es la composición de las inversas en el orden inverso. Este resultado puede extenderse a composiciones de tres o más transformaciones lineales; por ejemplo,
$$(T_3 \circ T_2 \circ T_1)^{-1} = T_1^{-1} \circ T_2^{-1} \circ T_3^{-1}$$

\newpage

\section{Cambio de base}

El cambio de base es un tema fundamental en álgebra lineal que se utiliza para relacionar las coordenadas de un espacio vectorial expresadas respecto a dos bases distintas. En otras palabras, el cambio de base permite transformar un vector de un espacio vectorial a otro espacio vectorial. La matriz del cambio de base es una herramienta matemática que se utiliza para transformar un vector de un espacio vectorial a otro espacio vectorial.

Para ilustrar el concepto de cambio de base, considere el siguiente ejemplo: Supongamos que tenemos un vector $\mathbb{v}$ expresado en términos de una base $\mathcal{B}_1$. Al cambiar a una nueva base $\mathcal{B}_2$, este vector se representaría mediante diferentes coordenadas, revelando cómo las bases afectan nuestra percepción y descripción de los objetos matemáticos. Para que nuestro ejemplo admita una representación geométrica, consideremos que
$$\mathcal{B}_1 = \left\{ e_1 = \begin{pmatrix}
    1 \\
    0
\end{pmatrix},  e_2 = \begin{pmatrix}
    0 \\
    1
\end{pmatrix} \right\} \quad \text{y} \quad \mathcal{B}_2 = \left\{ \mathbb{u}_1 = \begin{pmatrix}
    2 \\
    1
\end{pmatrix},  \mathbb{u}_2 = \begin{pmatrix}
    1 \\
    2
\end{pmatrix} \right\}$$

Estas dos bases se pueden representar de la siguiente manera:
\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[scale=1.4]
        \draw[-Stealth, thick] (-1,0) -- (3,0);
        \draw[-Stealth, thick] (0,-1) -- (0,3);

        \draw[-latex, thick] (0,0) -- (1,0) node[below] {$e_1$};
        \draw[-latex, thick] (0,0) -- (0,1) node[left] {$e_2$};

        \draw[-latex, thick] (0,0) -- (2,1) node[right] {$\mathbb{u}_1$};
        \draw[-latex, thick] (0,0) -- (1,2) node[right] {$\mathbb{u}_2$};
    \end{tikzpicture}
    \caption{Representación geométrica de las bases $\mathcal{B}_1$ y $\mathcal{B}_2$}
\end{figure}

Deseamos encontrar algo que nos permita expresar cualquier vector de $\mathcal{B}_1$ en términos de $\mathcal{B}_2$. Así, buscamos dos escalares tales que
\begin{align*}
    e_1 & = a \mathbb{u}_1 + b \mathbb{u}_2 \\
    & = a \begin{pmatrix}
        2 \\
        1
    \end{pmatrix} + b \begin{pmatrix}
        1 \\
        2
    \end{pmatrix} \\
    & = \begin{pmatrix}
        2a + b \\
        a + 2b
    \end{pmatrix}
\end{align*}
entonces $a = 2/3$ y $b = -1/3$. Por tanto,
\begin{equation}
    e_1 = \frac{2}{3} \mathbb{u}_1 - \frac{1}{3} \mathbb{u}_2 \label{JAJAJAJAJHGVVAHAV}
\end{equation}
De manera análoga,
\begin{align*}
    e_2 & = \alpha \mathbb{u}_1 + \beta \mathbb{u}_2 \\
    & = \alpha \begin{pmatrix}
        2 \\
        1
    \end{pmatrix} + \beta \begin{pmatrix}
        1 \\
        2
    \end{pmatrix} \\
    & = \begin{pmatrix}
        2\alpha + \beta \\
        \alpha + 2\beta
    \end{pmatrix}
\end{align*}
entonces $\alpha = -1/3$ y $\beta = 2/3$. Por tanto,
\begin{equation}
    e_2 = -\frac{1}{3} \mathbb{u}_1 + \frac{2}{3} \mathbb{u}_2 \label{HABAVXCAHAHHAHU}
\end{equation}
Así, con \eqref{JAJAJAJAJHGVVAHAV} y \eqref{HABAVXCAHAHHAHU} podemos expresar cualquier vector de $\mathcal{B}_1$ en términos de $\mathcal{B}_2$. Por ejemplo, si tenemos $\mathbb{v} = \begin{pmatrix}
    4 \\
    3
\end{pmatrix}$ de la base $\mathcal{B}_1$, podemos expresarlo en términos de la base $\mathcal{B}_2$ como sigue:
\begin{align*}
    \mathbb{v} & = 4 \begin{pmatrix}
        1 \\
        0
    \end{pmatrix} + 3 \begin{pmatrix}
        0 \\
        1
    \end{pmatrix} \\
    & = 4e_1 + 3e_2 \\
    & = 4 \left[ \frac{2}{3} \mathbb{u}_1 - \frac{1}{3} \mathbb{u}_2 \right] + 3 \left[ -\frac{1}{3} \mathbb{u}_1 + \frac{2}{3} \mathbb{u}_2 \right] \\
    & = \frac{5}{3} \mathbb{u}_1 + \frac{2}{3} \mathbb{u}_2
\end{align*}

Observemos la tabla \ref{JAJAJAVGQGTQGQa}, de donde se obtiene\sideTable[\label{JAJAJAVGQGTQGQa}]{
\centering
\begin{tabular}{ccc}
    \toprule
    & $\mathbb{u}_1$ & $\mathbb{u}_2$ \\
    \midrule
    $e_1$ & $2/3$ & $-2/3$ \\
    $e_2$ & $-1/3$ & $1/3$ \\
    \bottomrule
\end{tabular}
}
$$A = \begin{bmatrix*}[r]
    2/3 & -1/3 \\
    -1/3 & 2/3
\end{bmatrix*}$$
A la matriz anterior se le llama \textbf{matriz de transición} de la base $\mathcal{B}_1$ a la base $\mathcal{B}_2$. De esta manera,
\begin{align*}
    \mathbb{v}_{\mathcal{B}_2} & = A \mathbb{v}_{\mathcal{B}_1} \\
    & = \begin{bmatrix*}[r]
        -2/3 & -1/3 \\
        -1/3 & 2/3
    \end{bmatrix*} \begin{pmatrix}
        4 \\
        3
    \end{pmatrix} \\
    & = \begin{pmatrix}
        5/3 \\
        2/3
    \end{pmatrix}
\end{align*}
Además, observemos que
\begin{equation*}
    A^{-1} = \left[\begin{array}{cc}
        \tikzmarkin[ver=style azull]{col 1-b}2 & \tikzmarkin[ver=style azull]{col 2-b}1 \\
        1 \tikzmarkend{col 1-b} & 2\tikzmarkend{col 2-b} \\
    \end{array}\right]
    \tikz[overlay, remember picture]{
    \node[below=20pt of col 1-b.south west](A) {};
    \node[right=2pt of A] (B) {};
    \node[below=20pt of B] (C) {$\mathbb{u}_1$};
    \draw[-latex] (C) -- (B);

    \node[below=20pt of col 2-b.south west](D) {};
    \node[right=2pt of D] (E) {};
    \node[below=20pt of E] (F) {$\mathbb{u}_2$};
    \draw[-latex] (F) -- (E);
    }
\end{equation*}
\,\\ \,\\

Entonces, para cambiar de la base $\mathcal{B}_1$ a $\mathcal{B}_2$ usaremos la matriz $A$ y para cambiar de la base $\mathcal{B}_2$ a $\mathcal{B}_1$ usaremos la matriz $A^{-1}$.

\begin{example}
    Determine la matriz de transición de $\mathcal{B}_1 = \left\{ \begin{pmatrix}
        1 \\
        1
    \end{pmatrix},  \begin{pmatrix}
        2 \\
        3
    \end{pmatrix} \right\}$ a $\mathcal{B}_2 = \left\{ \begin{pmatrix}
        0 \\
        3
    \end{pmatrix},  \begin{pmatrix*}[r]
        5 \\
        -1
    \end{pmatrix*} \right\}$. \\
    \solucion Se quiere determinar la matriz $A$ de transición tal que
    \begin{center}
        \begin{tikzpicture}
            \node at (0,0) {$\mathcal{B}_1$};
            \node at (4,0) {$\mathcal{B}_2$};
            \draw[->,>=latex] (0.3,0) -- (3.7,0);
            \node[above] at (2,0) {$A$};
        \end{tikzpicture}
    \end{center}
    Sea $\mathcal{E} = \left\{ e_1,  e_2 \right\}$ la base canónica de $\RR[2]$, observemos que
    \begin{center}
        \begin{tikzpicture}[scale=1.2]
            \node at (0,0) {$\mathcal{E}$};
            \node at (4,0) {$\mathcal{E}$};
            \node at (0,2) {$\mathcal{B}_1$};
            \node at (4,2) {$\mathcal{B}_2$};
            \node[above] at (2,0) {$I$};
            \node[above] at (2,2) {$A$};
            \node[left] at (0,1) {$J$};
            \node[left] (A) at (3.9,1) {$H$};
            \node[right of = A,yshift=0.6] (B) {$H^{-1}$};
            \draw[->,>=latex] (0.3,0) -- (3.7,0);
            \draw[->,>=latex] (0.3,2) -- (3.7,2);
            \draw[->,>=latex] (0,1.7) -- (0,0.3);
            \draw[->,>=latex] (3.9,1.7) -- (3.9,0.3);
            \draw[<-,>=latex] (4.1,1.7) -- (4.1,0.3);
        \end{tikzpicture}
        %\captionof{figure}{~}
    \end{center}\newpage\noindent
    siendo $J = \begin{bmatrix}
        1 & 2 \\
        1 & 3
    \end{bmatrix}$ y $H = \begin{bmatrix*}[r]
        0 & -5 \\
        3 & -1
    \end{bmatrix*}$. Del diagrama anterior,
    $$A = H^{-1}IJ$$
    Notemos que ya tenemos $I$ y $J$, solo nos falta encontrar $H^{-1}$, pero es fácil determinar que
    $$H^{-1} = \begin{bmatrix*}[r]
        1/15 & 1/3 \\
        1/5 & 0
    \end{bmatrix*}$$
    Por tanto,
    \begin{align*}
        A & = H^{-1}IJ \\
        & = \begin{bmatrix*}[r]
            1/15 & 1/3 \\
            1/5 & 0
        \end{bmatrix*} \begin{bmatrix}
            1 & 0 \\
            0 & 1
        \end{bmatrix} \begin{bmatrix}
            1 & 2 \\
            1 & 3
        \end{bmatrix} \\
        & = \begin{bmatrix*}[r]
            2/5 & 17/15 \\
            1/5 & 2/5
        \end{bmatrix*}
    \end{align*}
    Por ejemplo, imaginemos que queremos expresar el vector $\begin{pmatrix*}[r]
        2 \\
        -1
    \end{pmatrix*}$ de la base $\mathcal{B}_1$ en la base $\mathcal{B}_2$, entonces
    $$\begin{bmatrix*}[r]
        2/5 & 17/15 \\
        1/5 & 2/5
    \end{bmatrix*} \begin{pmatrix*}[r]
        2 \\
        -1
    \end{pmatrix*}_{\mathcal{B}_1} = \begin{pmatrix*}[r]
        -1/3 \\
        0
    \end{pmatrix*}_{\mathcal{B}_2}$$
\end{example}

\section*{Generalizaciones}

Ahora, considere $\mathcal{B}_1$ y $\mathcal{B}_2$ cualesquiera dos bases (distintas a la canónica) en $\RR[n]$. Es decir, $\mathcal{B}_1 = \left\{ \mathbb{v}_1, \mathbb{v}_2, \dots, \mathbb{v}_n \right\}$ y $\mathcal{B}_2 = \left\{ \mathbb{w}_1, \mathbb{w}_2, \dots, \mathbb{w}_n \right\}$, y se quiere determinar la matriz de transición de la base $\mathcal{B}_1$ a la base $\mathcal{B}_2$. Consideremos el diagrama
\begin{center}
    \begin{tikzpicture}[scale=1.2]
        \node at (0,0) {$\mathcal{E}$};
        \node at (4,0) {$\mathcal{E}$};
        \node at (0,2) {$\mathcal{B}_1$};
        \node at (4,2) {$\mathcal{B}_2$};
        \node[above] at (2,0) {$I$};
        \node[above] at (2,2) {$A$};
        \node[left] at (0,1) {$J$};
        \node[left] (A) at (3.9,1) {$H$};
        \node[right of = A,yshift=0.6] (B) {$H^{-1}$};
        \draw[->,>=latex] (0.3,0) -- (3.7,0);
        \draw[->,>=latex] (0.3,2) -- (3.7,2);
        \draw[->,>=latex] (0,1.7) -- (0,0.3);
        \draw[->,>=latex] (3.9,1.7) -- (3.9,0.3);
        \draw[<-,>=latex] (4.1,1.7) -- (4.1,0.3);
    \end{tikzpicture}
    %\captionof{figure}{~}
\end{center}
siendo $\mathcal{E} = \left\{ e_1, e_2, \dots, e_n \right\}$. De esta forma, la matriz de transición $A$ está dada por
$$A = H^{-1}IJ$$

\begin{definition}
    La matriz de transición $A$ de la base $\mathcal{B}_1$ a $\mathcal{B}_2$ se define como la matriz cuyas columnas consisten en las coordenadas de los vectores de la base $\mathcal{B}_2$ expresados en términos de la base $\mathcal{B}_1$. 
\end{definition}

\begin{theorem}
    Sea $\mathcal{B}_1$ y $\mathcal{B}_2$ bases de un espacio vectorial $V$. Sea $A$ la matriz de transición de $\mathcal{B}_1$ a $\mathcal{B}_2$. Entonces para toda $\mathbb{x} \in V$,
    $$\mathbb{x}_{\mathcal{B}_2} = A\mathbb{x}_{\mathcal{B}_1}$$
\end{theorem}

\begin{theorem}
    Sea $A$ la matriz de transición de $\mathcal{B}_1$ a $\mathcal{B}_2$. Entonces $A^{-1}$ es la matriz de transición de $\mathcal{B}_2$ a $\mathcal{B}_1$.
\end{theorem}

\newpage
Sean $V$ y $W$ dos espacios vectoriales sobre $K$, con $\mathcal{B}_1 = \left\{ \mathbb{v}_1, \mathbb{v}_2, \dots, \mathbb{v}_n \right\}$ base de $V$ y $\mathcal{B}_2 = \left\{ \mathbb{w}_1, \mathbb{w}_2, \dots, \mathbb{w}_m \right\}$ base de $W$. Sea $T: V \longrightarrow W$ una transformación lineal tal que
$$T\mathbb{v}_1 = \chi_1, T\mathbb{v}_2 = \chi_2, \dots, T\mathbb{v}_n = \chi_n$$
Sea además
$$\chi_j = a_{1j}\mathbb{w}_1 + a_{2j}\mathbb{w}_2 + \cdots + a_{mj}\mathbb{v}_m, \quad \text{para } j = 1, 2, \dots, n$$
Ahora
$$(\chi_1)_{\mathcal{B}_2} = \begin{bmatrix} a_{11} \\ a_{21} \\ \vdots \\ a_{m1} \end{bmatrix}, (\chi_2)_{\mathcal{B}_2} = \begin{bmatrix} a_{12} \\ a_{22} \\ \vdots \\ a_{m2} \end{bmatrix}, \dots, (\chi_n)_{\mathcal{B}_2} = \begin{bmatrix} a_{1n} \\ a_{2n} \\ \vdots \\ a_{mn} \end{bmatrix}$$
Sea
\begin{align*}
    A & = \begin{bmatrix}
        (\chi_1)_{\mathcal{B}_2} & (\chi_2)_{\mathcal{B}_2} & \cdots & (\chi_n)_{\mathcal{B}_2}
    \end{bmatrix} \\
    & = \begin{bmatrix}
        a_{11} & a_{12} & \cdots & a_{1n} \\
        a_{21} & a_{22} & \cdots & a_{2n} \\
        \vdots & & \ddots & \\
        a_{m1} & a_{m2} & \cdots & a_{mn}
    \end{bmatrix}
\end{align*}
Además,
$$(\mathbb{v}_1)_{\mathcal{B}_1} = \begin{bmatrix}
    1 \\
    0 \\
    \vdots \\
    0 \\
    0
\end{bmatrix}$$
En general
\begin{center}
    \begin{tikzpicture}

        \node (A) at (0,0) {
        $(\mathbb{v}_j)_{\mathcal{B}_1} = \begin{bmatrix}
            0 \\
            0 \\
            \vdots \\
            1 \\
            \vdots \\
            0 \\
            0
        \end{bmatrix}$
        };
        \node[right = 30pt of A.east](L)  {$j$-ésimo elemento};
        \draw[->, >=stealth, shorten > =12pt, thick] (L.west) -- ($(A.east) + (-0.5,0)$);
    \end{tikzpicture}
\end{center}
entonces
\begin{align*}
    A(\mathbb{v}_j)_{\mathcal{B}_1} & = \begin{bmatrix}
        a_{1j} \\
        a_{2j} \\
        \vdots \\
        a_{mj}
    \end{bmatrix} \\
    & = (\chi_j)_{\mathcal{B}_2} \\
    & = (T\mathbb{v}_j)_{\mathcal{B}_2}
\end{align*}
Por tanto,
$$(T\mathbb{v}_j)_{\mathcal{B}_2} = A(\mathbb{v}_j)_{\mathcal{B}_1}, \text{ para } j = 1, 2, \dots, n$$
Ahora, sea $\mathbb{v} \in V$, entonces
$$\mathbb{v} = \alpha_1\mathbb{v}_1 + \alpha_2\mathbb{v}_2 + \cdots + \alpha_n\mathbb{v}_n$$
siendo $\alpha_i \in K$. Demostremos que
$$A(\mathbb{v})_{\mathcal{B}_1} = (T\mathbb{v})_{\mathcal{B}_2}$$
\newpage\noindent
Entonces
\begin{align*}
    A(\mathbb{v})_{\mathcal{B}_1} & = A(\alpha_1\mathbb{v}_1 + \alpha_2\mathbb{v}_2 + \cdots + \alpha_n\mathbb{v}_n)_{\mathcal{B}_1} \\
    & = A \big( \alpha_1(\mathbb{v}_1)_{\mathcal{B}_1} + \alpha_2(\mathbb{v}_2)_{\mathcal{B}_1} + \cdots + \alpha_n(\mathbb{v}_n)_{\mathcal{B}_1} \big) \\
    & = A \big( \alpha_1(\mathbb{v}_1)_{\mathcal{B}_1} \big) + A \big( \alpha_2(\mathbb{v}_2)_{\mathcal{B}_1} \big) + \cdots + A \big( \alpha_n(\mathbb{v}_n)_{\mathcal{B}_1} \big) \\
    & = \alpha_1 \big( A(\mathbb{v}_1)_{\mathcal{B}_1} \big) + \alpha_2 \big( A(\mathbb{v}_2)_{\mathcal{B}_1} \big) + \cdots + \alpha_n \big( A(\mathbb{v}_n)_{\mathcal{B}_1} \big) \\
    & = \alpha_1 (T\mathbb{v}_1)_{\mathcal{B}_2} + \alpha_2 (T\mathbb{v}_2)_{\mathcal{B}_2} + \cdots + \alpha_n (T\mathbb{v}_n)_{\mathcal{B}_2} \\
    & = \big( T(\alpha_1\mathbb{v}_1) \big)_{\mathcal{B}_2} + \big( T(\alpha_2\mathbb{v}_2) \big)_{\mathcal{B}_2} + \cdots + \big( T(\alpha_n\mathbb{v}_n) \big)_{\mathcal{B}_2} \\
    & = \big( T(\alpha_1\mathbb{v}_1) + T(\alpha_2\mathbb{v}_1) + \cdots + T(\alpha_n\mathbb{v}_n) \big)_{\mathcal{B}_2} \\
    & = \big( T(\alpha_1\mathbb{v}_1 + \alpha_2\mathbb{v}_2 + \cdots + \alpha_n\mathbb{v}_n) \big)_{\mathcal{B}_2} \\
    & = (T\mathbb{v})_{\mathcal{B}_2}
\end{align*}

\begin{example}
    Sea $T:\RR[2] \longrightarrow \RR[2]$ definida por $T\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} x-2y \\ 2x+y \end{pmatrix}$, siendo $\mathcal{B}_1 = \left\{ \begin{pmatrix*}[r] 1 \\ -2 \end{pmatrix*}, \begin{pmatrix} 3 \\ 2 \end{pmatrix} \right\} = \mathcal{B}_2$. Determinemos la matriz $A$ tal que
    $$A(\mathbb{v})_{\mathcal{B}_1} = (T\mathbb{v})_{\mathcal{B}_2}, \forall \mathbb{v} \in V$$
    Sean $\mathbb{v}_1 = \begin{pmatrix*}[r] 1 \\ -2 \end{pmatrix*}$, $\mathbb{v}_2 = \begin{pmatrix} 3 \\ 2 \end{pmatrix}$ elementos de la base $\mathcal{B}_1$ y sean $\mathbb{w}_1 = \begin{pmatrix*}[r] 1 \\ -2 \end{pmatrix*}$, $\mathbb{w}_2 = \begin{pmatrix} 3 \\ 2 \end{pmatrix}$ elementos de la base $\mathcal{B}_2$. Ahora
    \begin{align*}
        (T\mathbb{v}_1)_{\mathcal{B}_2} = \begin{pmatrix} 5 \\ 0 \end{pmatrix} & = a\mathbb{w}_1 + b\mathbb{w}_2 \\
        & = a \begin{pmatrix*}[r] 1 \\ -2 \end{pmatrix*} + b\begin{pmatrix} 3 \\ 2 \end{pmatrix} \\
        & = \begin{pmatrix} a+3b \\ -2a+2b \end{pmatrix}
    \end{align*}
    entonces obtenemos el siguiente sistema
    \begin{align*}
        a + 3b & = 5 \\
        -2a + 2b & = 0
    \end{align*}
    De la segunda ecuación se obtiene que $a = b$ y sustituyendo en la primer ecuación se obtiene que $b = 5/4$, de donde se sigue que $a = 5/4$. Entonces
    $$T(\mathbb{v}_1)_{\mathcal{B}_2} = \begin{bmatrix} 5/4 \\ 5/4 \end{bmatrix}$$
    De manera análoga,
    \begin{align*}
        (T\mathbb{v}_2)_{\mathcal{B}_2} = \begin{pmatrix*}[r] -1 \\ 8 \end{pmatrix*} & = a\mathbb{w}_1 + b\mathbb{w}_2 \\
        & = a \begin{pmatrix*}[r] 1 \\ -2 \end{pmatrix*} + b\begin{pmatrix} 3 \\ 2 \end{pmatrix} \\
        & = \begin{pmatrix} a+3b \\ -2a+2b \end{pmatrix}
    \end{align*}
    de donde se obtiene que $b = 3/4$ y $a = -13/4$. Entonces
    $$T(\mathbb{v}_2)_{\mathcal{B}_2} = \begin{bmatrix*}[r] -13/4 \\ 3/4 \end{bmatrix*}$$
    Por lo tanto,
    $$A = \begin{bmatrix*}[r]
        5/4 & -13/4 \\
        5/4 & 3/4
    \end{bmatrix*}$$
\end{example}

\newpage

\section{Ejercicios}

\noindent
De los problemas 1 al 39 determine si la transformación de $V$ en $W$ dada es lineal.

\begin{tasks}[
    style=enumerate,
    label-offset = 3mm,
    ](2)
    \task $T: \RR[2] \longrightarrow \RR$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=x$
    \task $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}x \\ 0\end{pmatrix*}$
    \task $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}1 \\ y\end{pmatrix*}$
    \task $T: \RR[2] \longrightarrow \RR$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=x+1$
    \task $T: \RR[3] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y \\ z\end{pmatrix*}=\begin{pmatrix*}x \\ y\end{pmatrix*}$
    \task $T: \RR[3] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y \\ z\end{pmatrix*}=\begin{pmatrix*}0 \\ y\end{pmatrix*}$
    \task $T: \RR[3] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y \\ z\end{pmatrix*}=\begin{pmatrix*}1 \\ z\end{pmatrix*}$
    \task $T: \RR[3] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y \\ z\end{pmatrix*}=\begin{pmatrix*}x \\ y+z\end{pmatrix*}$
    \task $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}x^{2} \\ y^{2}\end{pmatrix*}$
    \task $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}x \\ x/y\end{pmatrix*}$
    \task $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}y \\ x\end{pmatrix*}$
    \task $T: \RR[2] \longrightarrow \RR[4]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}x \\ x+y \\ y \\ x-y\end{pmatrix*}$
    \task $T: \RR[2] \longrightarrow \RR$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=x y$
    \task \!$T: \RR[n] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x_{1} \\ x_{2} \\ \vdots \\ x_{n}\end{pmatrix*}=\begin{pmatrix*} |x_{4}| \\ x_{1} \end{pmatrix*}$
    \task*(2) $T: \RR[n] \longrightarrow \RR$; $T\begin{pmatrix*}x_{1} \\ x_{2} \\ \vdots \\ x_{n}\end{pmatrix*}=x_{1}+x_{2}+\cdots+x_{n}$
    \task $T: \RR \longrightarrow \RR[n]$; $T(x)=\begin{pmatrix*}x \\ x \\ \vdots \\ x\end{pmatrix*}$
    \task $T: \RR[4] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y \\ z \\ w\end{pmatrix*}=\begin{pmatrix*}x+z \\ y+w\end{pmatrix*}$
\end{tasks}
\begin{enumerate}[start=18]
    \item $T: \RR[4] \longrightarrow \mathcal{M}_{2 \times 2}(\RR)$; $T\begin{pmatrix*}x \\ y \\ z \\ w\end{pmatrix*}=\begin{pmatrix*}x & z \\ y & w\end{pmatrix*}$
    \item $T: \mathcal{M}_{n \times n}(\RR) \longrightarrow \mathcal{M}_{n \times n}(\RR)$; $T(A)=A B$, donde $B$ es una matriz fija de $n \times n$
    \item $T: \mathcal{M}_{n \times n}(\RR) \longrightarrow \mathcal{M}_{n \times n}(\RR)$; $T(A)=A^{T} A$
    \item $T: \mathcal{M}_{p \times q}(\RR) \longrightarrow \mathcal{M}_{p \times q}(\RR)$; $T(A)=A^{T}$
    \item $T: \mathcal{M}_{m \times n}(\RR) \longrightarrow \mathcal{M}_{q \times n}(\RR)$; $T(A)=B A$, donde $B$ es una matriz fija de $q \times m$
    \item $T: D_{n} \longrightarrow D_{n}$; $T(D)=D^{2}$\infoBulle{$D_{n}$ es el conjunto de matrices diagonales de $n \times n$.}
    \item $T: D_{5} \longrightarrow \RR[3]$; $T(D)=\begin{pmatrix*}d_{11}+2 d_{33} \\ d_{22}-3 d_{33} \\ d_{55}\end{pmatrix*}$
    \item $T: P_{2} \longrightarrow P_{1}$; $T\left(a_{0}+a_{1} x+a_{2} x^{2}\right)=a_{0}+a_{1} x$
    \item $T: P_{2} \longrightarrow P_{1}$; $T\left(a_{0}+a_{1} x+a_{2} x^{2}\right)=a_{1}+a_{2} x$
    \item $T: P_{3} \longrightarrow \mathcal{M}_{2 \times 2}(\RR)$; $T\left(a_{0}+a_{1} x+a_{2} x^{2}+a_{3} x^{3}\right)=\begin{bmatrix*}a_{0}+a_{1} & a_{1}+a_{2} \\ a_{2}+a_{3} & a_{3}+a_{0}\end{bmatrix*}$
    \item $T: \RR \longrightarrow P_{n}$; $T(a)=a+a x+a x^{2}+\cdots+a x^{n}$
    \item $T: P_{2} \longrightarrow P_{4}$; $T\big(p(x)\big)=[p(x)]^{2}$
    \item $T: P_{2} \longrightarrow P_{4}$; $T\big(p(x)\big)=p(x)+x^{2} p(x)$
    \item $T: C[0,1] \longrightarrow C[0,1]$; $T_f=f^{2}(x)$
    \item $T: C[0,1] \longrightarrow C[0,1]$; $T_f=f(x)+1$
    \item $T: C[0,1] \longrightarrow C[0,1]$; $T_f=x^{2} f(x)+x f(x)$
    \item $T: C[0,1] \longrightarrow \RR$; $\displaystyle T_f=\int_{0}^{1} f(x) g(x) d x$, donde $g$ es una función fija en $C[0,1]$
    \item $T: C^{1}[0,1] \longrightarrow C[0,1]$; $\displaystyle T_f=\frac{d}{d x}\big(f(x) g(x)\big)$, donde $g(x)$ es una función fija en $C^{1}[0,1]$
    \item $T: C[0,1] \longrightarrow C[1,2]$; $T_f=f(x-1)$
    \item $T: C[0,1] \longrightarrow \RR$; $\displaystyle T_f=f\left(\frac{1}{2}\right)$
    \item $T: C^{1}[0,1] \longrightarrow \RR$; $\displaystyle T_f=\left.\left(\frac{d}{d x} f(x)\right)\right|_{x=1/2}$
    \item $T: \mathcal{M}_{n \times n}(\RR) \longrightarrow \RR$; $T(A)=\Det A$
    \item Sea $T: \RR[2] \longrightarrow \RR[2]$ dado por $T\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix*}[r] -x \\ -y \end{pmatrix*}$. Describa $T$ geométricamente.
    \item Sea $T$ una transformación lineal de $\RR[2] \longrightarrow \RR[3]$ tal que $T\begin{pmatrix*}1 \\ 0\end{pmatrix*}=\begin{pmatrix*}1 \\ 2 \\ 3\end{pmatrix*}$ y $T\begin{pmatrix*}0 \\ 1\end{pmatrix*}=\begin{pmatrix*}[r]-4 \\ 0 \\ 5\end{pmatrix*}$. Encuentre:
    \begin{tasks}(2)
        \task $T\begin{pmatrix*}2 \\ 4\end{pmatrix*}$
        \task $T\begin{pmatrix*}[r]-3 \\ 7\end{pmatrix*}$
    \end{tasks}
    \item Suponga que en un espacio vectorial real $V, T$ satisface $T(\mathbb{x}+\mathbb{y})=T \mathbb{x}-T \mathbb{y}$ y $T(\alpha \mathbb{x})=$ $\alpha T \mathbb{x}$ para $\alpha \geq 0$. Demuestre que $T$ es lineal.
    \item Encuentre una transformación lineal $T: \mathcal{M}_{3 \times 3}(\RR) \longrightarrow \mathcal{M}_{2 \times 2}(\RR)$.
    \item Si $T$ es una transformación lineal de $V$ en $W$, demuestre que $T(\mathbb{x}-\mathbb{y})=T \mathbb{x}-T \mathbb{y}$.
    \item Si $T$ es una transformación lineal de $V$ en $W$, demuestre que $T \mathbb{0}=\mathbb{0}$. ¿Son estos dos vectores cero el mismo?
    \item Sean $V$ y $W$ dos espacios vectoriales. Denote por $\mathcal{L}(V, W)$ el conjunto de transformaciones lineales de $V$ en $W$. Si $T_{1}$ y $T_{2}$ están en $\mathcal{L}(V, W)$, defina $\alpha T_{1}$ y $T_{1}+T_{2}$ por $\left(\alpha T_{1}\right) \mathbb{v}=$ $\alpha\left(T_{1} \mathbb{v}\right)$ y $\left(T_{1}+T_{2}\right) \mathbb{v}=T_{1} \mathbb{v}+T_{2} \mathbb{v}$. Pruebe que $\mathcal{L}(V, W)$ es un espacio vectorial.
\end{enumerate}\newpage\noindent
De los problemas 47 al 59 encuentre núcleo, imagen, rango y nulidad de la transformación lineal dada.
\begin{tasks}[
    start=47,
    style=enumerate,
    label-offset = 3mm,
    ](2)
    \task $T: \RR[2] \longrightarrow \RR$; $T\begin{pmatrix}x \\ y\end{pmatrix}=x$
    \task $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix}x \\ y\end{pmatrix}=\begin{pmatrix}x \\ 0\end{pmatrix}$
    \task $T: \RR[3] \longrightarrow \RR[2]$; $T\begin{pmatrix}x \\ y \\ z\end{pmatrix}=\begin{pmatrix}z \\ y\end{pmatrix}$
    \task $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix}x \\ y\end{pmatrix}=\begin{pmatrix*}[r]-4 y \\ y\end{pmatrix*}$
    \task $T: \RR[2] \longrightarrow \RR$; $T\begin{pmatrix}x \\ y\end{pmatrix}=x+y$
    \task $T: \RR[4] \longrightarrow \RR[2]$; $T\begin{pmatrix}x \\ y \\ z \\ w\end{pmatrix}=\begin{pmatrix}x+z \\ y+w\end{pmatrix}$
\end{tasks}
\begin{enumerate}[start=53]
    \item $T: \mathcal{M}_{2 \times 2}(\RR) \longrightarrow \mathcal{M}_{2 \times 2}(\RR)$; $T(A)=B A$, donde $B=\begin{bmatrix}1 & 0 \\ 3 & 1\end{bmatrix}$
    \item $T: \RR \longrightarrow P_3$; $T(a)=a+a x+a x^2+a x^3$.
    \item $T: \RR[2] \longrightarrow P_3$; $T\begin{pmatrix}a \\ b\end{pmatrix}=a+b x+(a+b) x^2+(a-b) x^3$
    \item $T: \mathcal{M}_{n \times n}(\RR) \longrightarrow \mathcal{M}_{n \times n}(\RR)$; $T(A)=A^{T}+A$
    \item $T: C^1[0,1] \longrightarrow C[0,1]$; $T_f=f^{\prime}$
    \item $T: C^2[0,1] \longrightarrow C[0,1]$; $T_f=f^{\prime \prime}$
    \item $T: C[0,1] \longrightarrow \RR$; $T_f=f(0)$
    \item Sea $T: V \longrightarrow W$ una transformación lineal, sea $\left\{\mathbb{v}_1, \mathbb{v}_2, \dots, \mathbb{v}_n\right\}$ una base para $V$ y suponga que $T \mathbb{v}_i=\mathbb{0}$ para $i=1,2, \dots, n$. Demuestre que $T$ es la transformación cero.
    \item Encuentre todas las transformaciones lineales de $\RR[2]$ en $\RR[2]$ tales que la recta $y=0$ se transforma en la recta $x=0$.
    \item Encuentre todas las transformaciones lineales de $\RR[2]$ en $\RR[2]$ que llevan a la recta $y=a x$ a la recta $y=b x$.
    \item Encuentre una transformación lineal $T$ de $\RR[3] \longrightarrow \RR[3]$ tal que
    $$\Nuc T=\left\{ \begin{pmatrix} x \\ y \\ z \end{pmatrix} \mid 2 x-y+z=0\right\} .$$
    \item Encuentre una transformación lineal $T$ de $\RR[3] \longrightarrow \RR[3]$ tal que
    $$\Ima T=\left\{\begin{pmatrix} x \\ y \\ z \end{pmatrix} \mid 3 x+2 y-5 z=0\right\} .$$
\end{enumerate}
De los problemas 65 al 86 encuentre la representación matricial $A_{T}$ de la transformación lineal $T$, $\Nuc T$, $\Ima T$, $\nu(T)$ y $\rho(T)$. A menos que se especifique otra cosa, suponga que $\mathcal{B}_1$ y $\mathcal{B}_2$ son bases canónicas.
\begin{enumerate}[resume]
    \item $T: \RR[2] \longrightarrow \RR$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=3 x-2 y$
    \item $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}x-2 y \\ -x+y\end{pmatrix*}$
    \item $T: \RR[2] \longrightarrow \RR[3]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}x+y \\ x-y \\ 2 x+3 y\end{pmatrix*}$\newpage
    \item $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}y \\ x\end{pmatrix*}$
    \item $T: \RR[3] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y \\ z\end{pmatrix*}=\begin{pmatrix*}x-y+z \\ -2 x+2 y-2 z\end{pmatrix*}$
    \item $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}a x+b y \\ c x+d y\end{pmatrix*}$
    \item $T: \RR[2] \longrightarrow \RR[3]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}x+y \\ 3 x-2 y \\ y-x\end{pmatrix*}$
    \item $T: \RR[3] \longrightarrow \RR[3]$; $T\begin{pmatrix*}x \\ y \\ z\end{pmatrix*}=\begin{pmatrix*}[r]x-y+2 z \\ 3 x+y+4 z \\ 5 x-y+8 z\end{pmatrix*}$
    \item $T: \RR[3] \longrightarrow \RR[3]$; $T\begin{pmatrix*}x \\ y \\ z\end{pmatrix*}=\begin{pmatrix*}-x+2 y+z \\ 2 x-4 y-2 z \\ -3 x+6 y+3 z\end{pmatrix*}$
    \item $T: \RR[4] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y \\ z \\ w\end{pmatrix*}=\begin{pmatrix*}x+z \\ 5 w-4 y\end{pmatrix*}$
    \item $T: \RR[4] \longrightarrow \RR[4]$; $T\begin{pmatrix*}x \\ y \\ z \\ w\end{pmatrix*}=\begin{pmatrix*}x-y+2 z+w \\ -x+z+2 w \\ x-2 y+5 z+4 w \\ 2 x-y+z-w\end{pmatrix*}$
    \item $T: \RR[4] \longrightarrow \RR[2]$; $T\begin{pmatrix*}w \\ x \\ y \\ z\end{pmatrix*}=\begin{pmatrix*}a w+b x \\ c y+d z\end{pmatrix*}$
    \item $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}[r]3 x+2 y \\ -5 x-4 y\end{pmatrix*}$; $\mathcal{B}_1=\mathcal{B}_2=\left\{\begin{pmatrix*}[r]3 \\ -2\end{pmatrix*},\begin{pmatrix*}[r]-1 \\ 1\end{pmatrix*}\right\}$
    \item $T: \RR[2] \longrightarrow \RR[2]$; $T\begin{pmatrix*}x \\ y\end{pmatrix*}=\begin{pmatrix*}4 x-y \\ 3 x+2 y\end{pmatrix*}$; $\mathcal{B}_1=\mathcal{B}_2=\left\{\begin{pmatrix*}[r]-1 \\ 1\end{pmatrix*},\begin{pmatrix*}4 \\ 3\end{pmatrix*}\right\}$
    \item $T: P_{2} \longrightarrow P_{3}$; $T\left(a_{0}+a_{1} x+a_{2} x^{2}\right)=a_{1}-a_{1} x+a_{0} x^{3}$
    \item $T: \RR \longrightarrow P_{3}$; $T(a)=a+a x+a x^{2}+a x^{3}$
    \item $T: P_{2} \longrightarrow \RR[2]$; $T\left(a_{0}+a_{1} x+a_{2} x^{2}\right)=\begin{pmatrix*}a_{0}+a_{1} \\ a_{1}+a_{2}+a_{3}\end{pmatrix*}$
    \item $T: P_{3} \longrightarrow P_{1}$; $T\left(a_{0}+a_{1} x+a_{2} x^{2}+a_{3} x^{3}\right)=\left(a_{1}+a_{3}\right) x-a_{2}$
    \item $T: P_{4} \longrightarrow P_{4}$; $T\left(a_{0}+a_{1} x+a_{2} x^{2}+a_{3} x^{3}+a_{4} x^{4}\right)=a_{4} x^{4}+a_{2} x^{2}+a_{0}$
    \item $T: \mathcal{M}_{2 \times 2}(\RR) \longrightarrow \mathcal{M}_{2 \times 2}(\RR)$; $T\begin{bmatrix*}a & b \\ c & d\end{bmatrix*}=\begin{bmatrix*}a-b+2 c+d & -a+2 c+2 d \\ a-2 b+5 c+4 d & 2 a-b+c-d\end{bmatrix*}$
    \item $T: P_{4} \longrightarrow P_{3}$; $T\left(a_{0}+a_{1} x+a_{2} x^{2}+a_{3} x^{3}+a_{4} x^{4}\right)=a_{3} x^{3}+a_{1} x$
    \item $T: \mathcal{M}_{2 \times 3}(\RR) \longrightarrow \RR[3]$; $T\begin{bmatrix*}a & b & c \\ d & e & f\end{bmatrix*}=\begin{pmatrix*}a+e \\ b+f \\ c+d\end{pmatrix*}$
\end{enumerate}